Teacher:陈向群，刘先华
# 课程导论
## 1.课程起源
## 2.课程规划
上半学期：2-6章（硬件）
下班学期：7-12章（软件）
11.6期中考试
## 3.五个有趣的现实问题
1. 整型不是整数，浮点型不是实数。
	1. x^2>=0永远成立吗？ **对于整型，有上界溢出**
	2. 是否满足结合律？ **浮点型**
	**计算机系统中的算术不等于数学中的算数**，有些性质在计算机系统中不成立。
	- 计算机系统只能表示有限大小的数。
	- 浮点型不满足结合律：舍入操作或造成精度误差。
	- 需要记住计算机中不同数据类型所满足的数学性质。
2. 了解汇编
	- 帮助查找底层实现的相关的程序错误（bug）。
	- 程序性能调优。
	- 系统软件或嵌入式软件开发。
## 4.课程主体内容
==ISA：指令集体系结构==。
## 5.注意事项
期中15+实验30+平时15+期末40
# 第二章.信息的表示和处理 
## 1.信息存储
### 1.1十六进制表示法
### 1.2子数据大小
1byte=8bits
不同类型数据对应不同的字节数。比如int型和float型对应4个字节，char型和double型对应8个字节（在64位系统中）。 
区分大小端：
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309232220836.png)

### 1.3寻址和子节顺序
### 1.4表示字符串
### 1.5表示代码
### 1.6布尔代数
### 1.7位级运算
`& | ~ ^ `对位分别进行不同的运算。
集合与子集（离散数学基础）
### 1.8逻辑运算
`&& ||  |`
### 1.9移位运算
`<< >>`：
##### 逻辑运算
##### 算术运算
## 2.整数表示
### 2.1整型数据类型
#### unsigned
直接根据每一位二进制计算即可。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309131339834.png)
最小：0
最大：2^w-1
#### signed
最高位代表的数要减去。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309131339314.png)
变负数：取反+1。
最小：-2^(w-1)
最大：2^(w-1)-1
**有符号与无符号之间的转换**
### 2.2 无符号数的编码
### 2.3补码编码
### 2.4转换和映射
保持位的表示，然后重新解读。
从模的角度设计的：
**有符号->无符号的转换：>0的就相等，<0的相差2^k（+2^k)
无符号->有符号的转换：>0的就相等，<0的相差2^k**
==C语言中==：默认为有符号数。存在缺省转换。
### 2.5有符号数与无符号数的比较（重）
无符号与有符号的比较原理。
### 2.6扩展(Expanding)和截断（Truncating）
#### 扩展
目的：扩展到更长的数，但是值不变。
方法：
- 无符号的最高位不断加0
- 有符号的**符号位**拷贝，放到扩展的位子上。发现结果确实不会变化。**故其实际上是符号位的扩展。**
应用：从小的数据类型（比如short int）转换为更大的数据类型（比如int）：
```c++
short int x=15213;
int ix=(int)x;
short int y=-15213;
int iy=(int)y;
//只需要按照上面所说的符号位扩展对x,y进行补足
```
#### 截断
- 无符号的Mod $2^k$。
- 有符号的:先mod $2^k$，再将得到的无符号数转化为补码。
比如10->-6,-10->6。
## 3.整数运算
### 3.1无符号加法
- 无符号的
	- 有进位。
	- 最高位进位不考虑，直接忽略。
	- 溢出的情况：溢出的部分也会映射到Modular Sum（直接减去2^w）
	- 求反： x(x=0);2^w-x(x>0)。
### 3.2补码加法
- 有符号的
	- 有进位。
	- 溢出（Overflow）：正或负溢出都要进行映射。
		- 正溢出：x+y-$2^w$
		- 负溢出：x+y+$2^w$
		- s=x+y(t~w)；s<=0 正溢出； s>=0 负溢出。 
### 3.3补码的非
$$ -x=\left\{
\begin{matrix}
 TMin , x= TMin\\
 -x , x>TMin
\end{matrix}
\right.
$$
### 3.4无符号乘法
$x*y=(x.y)mod 2^w$
### 3.5补码乘法
$x*y=U2T((x.y)mod2^w)$
注意：==无符号和补码乘法的位级等价性==。
### 3.6 乘以常数
 乘以2的幂：左移k位
### 3.7 除以2的幂
 除以2的幂：右移k位。且对于补码来说，为了让负数仍为负，应当为算术右移。
 ### 3.8总结
事实上，计算机执行的整数运算实际上是一种**模运算**形式。
## 4.浮点数
### 4.1二进制小数
类比十进制的小数表示方式。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309181321436.png)
- （无符号）除2相当于右移。
- （无符号）乘2相当于左移。
-   数字0.11111111...（2进制）始终小于1.0（无限接近） 1.0-ε
### 4.2IEEE浮点表示
%%我们希望制定一个统一的标准,IEEE应运而生%%
IEEE浮点标准用V=(-1)^s \* M \* 2^E 的形式来表示一个数。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309181350808.png)
- 符号（sign）： s决定是负数还是正数，而对于数值0 的符号位解释作为特殊情况处理。
- 尾数（significand）：M是一个==二进制小数==，它的范围是1~2-ε，或者是0~1-ε
- 阶码（exponent）：E对浮点数进行加权，这个权重是2的E次幂（可能是负数）
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309181333653.png)
#### ①规格化的值
exp的位模式不全为0，也不全为1。
- 阶码字段被解释为以bias（偏置）形式表示的有符号证书，也就是说，阶码的值E=e-Bias，其中e是无符号数，其表示为从0到k-1位$e(k-1)~...e0~$；而Bias是一个等于2^(k-1)-1的偏置值。
- 小数字段frac被解释为描述小数值f，其中0<=f<1，其二进制表示为$0.f(n-1)~...f1~f0~$。尾数定义为M=1+f。这种方式叫做**隐含的1开头的表示**。因此把M看做二进制表示下的1.f(n-1)...f(0)。
#### ②非规格化的值
阶码域全为0。
- 阶码值为E=1-Bias。
- 尾数值为M=f，也就是小数字段的值，不包含隐含的开头的1。这样可以方便表示0（M不大于1）
##### 功能
- 提供了一种表示数值0的方法。
- 表示那些非常接近于0.0的数。它们提供了一种属性，称为**逐渐溢出**，其中，可能的数值分布均匀地接近于0.0。
#### ③特殊值
阶码全为1。
##### 小数域全为1
得到的值表示无穷：
s=0时正无穷；s=1时负无穷。
**无穷能够表示==溢出==的结果。**
##### 小数域为非0
值被称为==“NaN”（非数）==。一些运算的结果不能是实数或无穷，就会返回这样的NaN值。
### 4.3数字示例
对于以上几种IEEE浮点表示，我们分别有不同的最小值和最大值。
### 4.4舍入（rounding）
- ==向偶数舍入（向最接近的值舍入）==
- 向0舍入
- 向下舍入
- 向上舍入
### 4.5浮点运算
#### 乘法
- s=s1^s2
- M=M1 \* M2 当M>=2，右移。
- E=E1+E2
满足单调性
#### 加法
难度在于运算不满足结合律。（但是可交换）
且浮点数在加法运算下一般是存在逆元的，无穷和NaN例外。
### 4.6C语言中的浮点数
当在int/float/double格式之间进行强制类型转换时，程序改变数值和位模式的原则是（假设int 32位）：
- int->float 数字不会溢出，但是可能被舍入。
- int/float->double double有更大范围和精度，所以能够保留精确的数值。
- double->float 值可能溢出为无穷，也有可能被舍入。
- float/double->int 值会向0舍入。
## 5.总结
大多数机器对整数使用补码编码，而对浮点数使用 IEEE 标准 754 编码。
# 第三章.程序的机器级表示
## 1.历史观点
Intel处理器
## 2.程序编码
`linux> gcc -Og -o p p1.c p2.c`
启动GCC C 编译器，生成符合原始c代码整体结构的机器代码的优化等级。
过程：
1. C**预处理器**扩展源代码，插入所有用#include命令指定的文件，并扩展所有用#define声明指定的宏。
2. **编译器**产生两个源文件的**汇编代码**，名字分别为p1.s,p2.s。
3. **汇编器**将汇编代码转化成二进制**目标代码**文件p1.o,p2.o。
4. **链接器**将两个目标代码文件与实现库函数的代码合并，产生最终可执行代码文件p(-o p产生)。
### 2.1 机器级代码
ISA：指令集体系结构或指令集架构。
x86-64的机器代码与原始的C代码差别非常大，一些通常对C语言程序员隐藏的处理器状态：
- **程序计数器**（PC）给出将要执行的下一条指令在内存中的地址。
- 整数**寄存器文件**包含16个命名位置，分别存储64位的值。
- **条件码寄存器**保存最近执行的算术或逻辑指令的状态信息。
- 一组向量寄存器可以存放一个或多个整数或浮点数值。
程序内存包括：程序的可执行机器代码，操作系统需要的一些信息，用来管理过程调用和返回的运行时栈，用户分配的内存块。
一条机器指令只执行一个非常基本的操作。
### 2.2 代码示例
- “-S”选项可以看到C语言编译器产生的汇编代码。`linux> gcc -Og -S mstore.c`
- "-c"选项使GCC编译并汇编该代码。（生成.o文件）
- “-d”标志的程序可以根据机器代码产生一种类似于汇编代码的格式`linux> objdump -d mstore.o` （一种转化的解释，比如53开头字节值对应指令pushq %rbx）。==反汇编器：查看机器代码文件（可执行代码）的内容。==
### 2.3 关于格式的注解
对于一些应用程序，程序员必须用汇编代码来访问机器的积极特性：
- 用汇编代码编写整个函数
- 利用GCC的支持，直接在C程序中嵌入汇编代码
## 3.数据格式
- 字（word）：16位数据类型
- 双字（double word）：32位
- 四字（quad words）：64位
x84-64中，数据类型long实现为64位，int存储为32位。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309201404236.png)
浮点数有单精度（4字节）值和双精度（8字节）值。
大多数GCC产生的汇编代码指令都有一个字符的后缀，表示操作数的大。例如mov的变种：movb movw movl movq
## 4.访问信息
CPU包含一组16个存储64位值的**通用目的寄存器**，用来存储整数数据和指针，名字都以%r开头。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309201411387.png)
==以上，记住目前使用的**64位寄存器**。==
### 4.1 操作数指示符
操作数（operand）：指示出执行一个操作中要使用的源数据值，以及放置结果的目的位置。按照源数据值不同的操作数的可能性分为三种类型。
- **立即数**：表示常数值。格式见图
- **寄存器**：表示某个寄存器的内容，16个寄存器的低位1字节、2字节、4字节、8字节中的一个座位操作数，对应于8、16、32、64位。
- **内存引用**：根据有效地址访问某个内存位置。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309201416203.png)
### 4.2 数据传送指令
==MOV类==
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309201417465.png)
源操作数指定的值是一个**立即数**，存储在寄存器或内存中，目的操作数指定一个位置，寄存器或内存地址。
==从Source->Destination==。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309201419607.png)
立即数、寄存器、内存之间的移动↑
### 4.3 数据传送示例
### 4.4 压入和弹出栈数据
## 5.算术和逻辑操作
### 5.1 加载有效地址
### 5.2 一元和二元操作
### 5.3 移位操作
### 5.4 讨论
### 5.5 特殊的算术操作
## 6.控制
### 6.1 条件码
除了整数寄存器，CPU还维护着一组单个位的**条件码**寄存器，可以执行这些寄存器来执行条件分支指令。常用的有：
- CF：进位标志。可以用来检查无符号操作的溢出。
- ZF：零标志。最近的操作得出的结果为0。
- SF：符号标志。最近的操作得到的结果为负数。
- OF：溢出标志。最近的操作导致一个补码溢出——正溢出或负溢出。
==注意：leaq指令不改变任何条件码==，除此之外，大部分指令都会设置条件码。
除了以上几个之外，还有两类指令（CMP和TEST），它们只设置条件码而不改变任何其他寄存器。
### 6.2 访问条件码
常用的读取方法有三种：
1. 根据条件码的某种组合，将一个字节设置为0或1.（==称这一类指令为SET指令==）
2. 可以条件跳转到程序的某个其他的部分。
3. 可以有条件地传送数据。
这些SET指令的后缀表示不同的条件而不是操作数大小，比如setl和setb表示“小于时设置（set less）”和“低于时设置（set below）”。
一条SET指令的目的操作数是==低位单字节寄存器元素==之一，或是==一个字节的内存位置==。
某些底层的机器指令可能有多个名字，我们称之为“同义名”。
### 6.3 跳转指令
**跳转（jump)** 指令会导致执行切换到程序中的一个全新位置。在汇编代码中，这些跳转的目的地通常用一个**标号（label）** 指明。
#### 直接跳转
#### 间接跳转
### 6.4 跳转指令的编码
跳转指令有几种不同的编码，但是最常用的都是PC-relative的：==将目标指令的地址与紧跟在跳转指令后面那条指令的地址之间的差座位编码==。
另一种编码方法是给出“绝对地址”。
当执行PC相对寻址时，**程序计数器的值是跳转指令后面的那条指令的地址，而不是跳转指令本身的地址。**
### 6.5 用条件控制来实现条件分支
将条件表达式和语句从C语言翻译成机器代码，最常用的方式是结合有条件和无条件跳转。
if else的逻辑：汇编器为then-statement和else-statement各自产生的代码块，它会插入条件和无条件分支，以保证能够执行正确的代码块。
### 6.6 用条件传送来实现条件分支
实现条件操作的传统方法：通过使用==控制==的条件转移。
另一种替代的策略：使用==数据==的条件转移。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309251439476.png)
### 6.7 循环
#### do-while循环
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309251442054.png)
#### while循环
##### 编译1
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309251443660.png)
##### 编译2（guarded-do）
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309251444503.png)
#### for循环
##### 编译1
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309251446988.png)
##### 编译2
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202309251446460.png)

### 6.8 switch语句
==multiway branching多重分支==
==jump table跳转表==：一个数组，表项i是一个代码段的地址。

## 7.过程
### 7.1 运行时栈
### 7.2 转移控制
### 7.3 数据传送
### 7.4 栈上的局部存储空间
### 7.5 寄存器中的局部存储空间
### 7.6 递归过程
## 8.数组分配和访问
### 8.1 基本原则
### 8.2 指针运算
### 8.3 嵌套的数组
### 8.4 定长数组
### 8.5 变长数组
## 9.异质的数据结构
### 9.1 结构
### 9.2 联合
### 9.3 数据对齐
## 10.在机器级程序中将控制和数据结构起来
### 10.1 理解指针
### 10.2 应用：使用GDB调试器
### 10.3 内存越界引用和缓冲区溢出
### 10.4 对抗缓冲区溢出攻击
### 10.5 支持变长栈帧
## 11.浮点代码
### 11.1 浮点传送和转换操作
### 11.2 过程中的浮点代码
### 11.3 浮点运算操作
### 11.4 定义和使用浮点常数
### 11.5 在浮点代码中使用位级操作
### 11.6 浮点比较操作
### 11.7 对浮点代码的观察结论
## 12.小结
# 第五章 程序性能优化
## 1.编译器优化的局限（制约）
### 1.1 常见的几类优化
- -Og
- -O1（常用）
- -O2（可接受）
- -O3
>一步步提高程序性能，但也可能增加程序规模。我们会限制优化级别。
**编译器的优化必须是==安全==的优化**
### 1.2 内存别名使用
这是一个制约因素，由于不知道是否会引用同一片内存，所以编译器不会贸然进行优化。
### 1.3 函数调用
#### 分析
假如f()中有对全局变量的改变，那么有些优化就会出错，比如原来是f()+f()+f()，改成f()\*3就会出错，所以不能这样优化。
#### 改进
可以通过**内联函数**来优化，即把函数展开，将函数调用替换为函数体，这样既减少了函数调用的开销，也允许对展开的代码做进一步优化。
在某些情况下，最好能阻止编译器执行内联替换：
- 符号调试器来评估代码，比如GDB。（如果一个函数调用已经用内联替换优化过了，那么任何对这个调用进行追踪或者设置断点的尝试都会失败）。
- 用代码剖析的方式来评估程序性能。
## 2.表示程序性能
**CPE**：Cycles Per Element，每元素的周期数=Total Cycles/Number of Elements.
**最小二乘拟合**求运行时间y与被处理元素个数n的关系，得到的y=kn+b中，k即为CPE的有效值。
## 3.现代处理器
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202013086.png)
### 3.1 架构（ICU和EU）
超标量：**乱序的**
#### 3.1.1控制单元ICU
##### 取指控制
- ICU从**指令高速缓存**（包含最近访问的指令）中读取指令，一般会较早取指，保证有足够时间译码并发送操作到EU。
- 分支预测：猜测是否选择分支以及分支的目标地址。
	- 投机执行：处理区取出位于它预测分支调到的指令，并对指令译码，并进行操作。
	- 如果过后确定分支预测错误，状态重新回到设置分支之前状态。
##### 指令译码
- 接受实际程序指令->转换成一组基本操作（**微操作**）。
	- 把内存引用和算术运算分开：**加载、运算、存回**。
##### 退役单元
记录正在进行的处理，确保它遵守机器级程序的**顺序语义**，会控制寄存器文件的更新。
- 指令译码时，指令信息存放在队列中，直到发生以下结果中一个：
	- 指令操作完成，并且引起指令的分支点预测正确，那么指令**退役**，==并且对寄存器更新可以实际执行==。
	- 或者预测错误，指令被**清空**，丢弃所有计算出来的结果。
#### 3.1.2 执行单元EU
##### 基本功能单元
- 多个操作分配到一组专门用来处理不同类型操作的**功能单元**中。
	- 加载单元：读内存到处理器。有一个加法器完成地址运算。
	- 存储单元：写数据到内存。有一个加法器完成地址运算。
- 加载和存储单元通过**数据高速缓存**（高速存储器，存放着最近访问过的数据值）来访问内存。
- 投机执行技术求值，最终结果不会存放在程序寄存器或内存中，直到EU确定分支预测是否正确，处理器确定能实际执行再执行。如果预测错误，分支单元开始在新的位置取指。
- 不同的功能单元被设计来执行不同的操作。
##### 寄存器重命名
**寄存器重命名**：控制操作数在执行单元间传送的常见机制。
- 当产生一条更新寄存器r的指令译码时，产生标记t，得到一个指向该操作结果的唯一标识符。**条目(r,t**)加入一张表中。
- 以寄存器r作为操作数的指令译码时，发送到执行单元的操作会包含t作为操作数源的值。
- 完成第一个操作，得到结果(**v,t**)。指明标记为t的操作产生值v，所有等待t作为源的操作都能使用v作为源值。（==数据转发==）
- 这样，值可以从一个操作直接转发到另一个操作。
### 3.2 功能单元的性能
- 延迟latency：完成运算需要总时间。
- 发射时间issue time：两个连续同类型的运算之间需要的最小时钟周期数。
	- 发射时间为1 的功能单元被称为是**完全流水线化的**。
	- **最大吞吐量**：发射时间的倒数。==一个完全流水线化的功能单元有最大的吞吐量==。
		- **具有多个功能单元可以进一步提高吞吐量**。
		- 吞吐量可能为每时钟周期C/I（C为容量，I为发射时间）
- 容量capacity：能够执行该运算的功能单元的数量。（同时能够发射多少个这样的操作）
- CPE的两个基本界限反映以上性能的影响：
	- 延迟界限：按照严格顺序完成合并运算的函数所需的最小CPE值。
	- 吞吐量界限：给出了CPE的最小界限。（由于需要利用加载单元从内存中读数据带来的限制，加载单元的个数限制了每个时钟周期读取数值的个数）
### 3.3 抽象模型
#### 3.3.1 从机器级代码到数据流图
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202059991.png)
乘法被扩展为load和mul操作
- 四类寄存器
	- 只读：只用作源值，也可以作为数据或计算内存地址，但是不会被修改，比如循环combine4中的%rax
	- 只写：作为数据传送操作的目的
	- 局部：循环内部被修改和使用，比如combine4循环中的条件码寄存器cmp修改，jne使用（**在单次迭代之内**）
	- 循环：既为源值，也为目的。一次迭代中产生的值会在另一次迭代中用到。
- **循环寄存器之间的操作链限制性能的数据相关**。
- 画出combine4内循环的n次迭代计算的数据流表示，假设乘法延迟为5个周期，加法延迟为1个周期，那么左边也就是**乘法操作的序列形成了限制性能的关键路径**。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202105441.png)
左边链为关键路径，右边链以及循环中其他操作以及从内存中读取数据，都可以与乘法器并行进行。
- 对于所有情况，如果运算的延迟L>1，（计算n个元素的乘积或者和大约需要L\*n+K个时钟周期，L是合并运算的延迟，K是调用函数和初始化以及终止循环的开销）那么可以看到测量出来的CPE就是L，表明这个链是制约性能的关键路径。
#### 3.3.2其他性能因素
- 数据流中关键路径提供的只是程序需要周期数的**下界**。还有其他限制因素。
- 可以的功能单元的数量和任何一步中功能单元之间能够传递数据值的数量，会限制性能。
- **延迟界限**是基本的限制，决定了我们的合并操作能执行多块，优化操作是调整结构，增强指令并行性，使唯一限制变成**吞吐量界限**。
### 3.4 性能进阶
#### 3.4.1 提高程序性能的措施
##### 1.消除循环的低效率
- 对strlen(s)的使用。
- 某些重复出现在循环中的不变量，可以跳出循环。 **代码移动**
##### 2.减少过程调用
尽量减少对函数的调用。比如说：我们不要函数调用来获取向量元素，而是直接访问数组。
##### 3.消除不必要的内存引用
可以最后再**写回内存**。
但是注意内存别名可能会引起的错误。
##### 4.循环展开（重）
循环展开，减少循环的迭代次数：
- 减少了循环索引计算和条件分支计算。
- 提供了进一步变化代码从而减少整个计算中关键路径上的操作数量。
- 但是，这样的循环展开不能将性能改进到超过延迟界限。**关键路径**是性能制约因素。
- 我们需要进行改进，突破延迟界限，使得吞吐量界限（加载内存）成为其唯一界限。需要**提高并行性**。
###### 方法一.使用多个累计变量
对于可结合或可交换的合并运算，比如整数加法或乘法，我们可以通过将一组合并运算分割成两个或者更多的部分，并在最后合并结果来提高性能。
比如：
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202125578.png)
从2x1循环展开变成2x2循环展开：
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202126454.png)
由于每次两个vmulsd运算之间没有数据相关，每个关键路径只含n/2个操作，CPE就可以变为L/2.(2x1->2x2的情况下)如果改成kxk循环展开，可知当k足够大时，程序在所有情况下都能达到吞吐量界限（1.00）。==这就要求循环展开因子k>=C\*L==。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202129208.png)
###### 方法二.重新结合变换
从`acc=(acc OP data[i]) OP data[i+1]`
变为`acc=acc OP(data[i] OP data[i+1])`
差别在于两个括号是如何放置的，相当于改为了**2x1a**的循环展开形式。
效果惊人！！
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202132396.png)
两次Load和一次mul数据相关，关键路径上的n次操作变为n/2
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202135460.png)
#### 3.4.2 限制因素
##### 1.寄存器溢出
如果并行度p超过可用寄存器数量，某些临时值会放到内存，使CPE变差。
##### 2.分支预测和预测错误的惩罚
不要过分关注可预测分支：在大的循环中，只有最后一步会预测错误。
tip:书写更适合用于条件传送实现的代码，更“功能性”风格：
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311202142277.png)
### 3.5 理解内存性能
#### 3.5.1 加载的性能
测试表示延时为4
#### 3.5.2 存储的性能
存储操作延时为1，它不影响其他寄存器的值，但会影响它后面的加载操作。
# 第八章 异常控制流ECF
## 1.异常 Exception
### 1.1 引入介绍
异常控制流，用来相应处理器状态中的某些变化。
- 当前**状态**：处理器正在执行某个当前指令Icurr。
- 状态变化称为**事件**。
- 当处理器检测到有事件发生，它就会通过一张叫做**异常表**的跳转表，进行一个间接过程调用，到**异常处理程序exception handler**中处理这类事件。
- 处理完毕后，会发生以下1种
	- 处理程序将控制返回给当前指令Icurr。
	- 处理程序将控制返回给Inext(如果没有异常将会执行的下一条指令)
	- 处理程序终止被中断的程序
### 1.2 异常处理
- 系统为每种类型的异常都分配了一个唯一的非负整数的**异常号exception number**.
	- 一些号码由处理器的设计者分配，如零除、缺页、内存访问违例、断点以及算术运算溢出。
	- 其他号码由操作系统**内核**的设计者分配，包括系统调用和来自外部I/O设备的信号。
- 系统启动时，初始化一张**异常表**，使得表目k包含异常k的处理程序的==地址==。
	- 异常表的起始地址放在一个叫做**异常表基址寄存器exception table base register**D==特殊==CPU寄存器中。
	- 异常表基址寄存器+异常号\*4，在异常表中进行寻找。
- 处理器检测到事件后，确定相应的异常号k，随后根据表目k间接过程调用到相应处理程序。
- 类似于过程调用，但有一些不同
	- 过程调用时会将返回地址压栈，而异常会根据自己的类型确定返回地址。
	- 处理器也会把一些额外的处理器状态压到栈里。
	- 如果控制从用户程序转移到内核，所有这些项目都被压到**内核栈**中，而不是压到**用户栈**中。
	- 异常处理程序运行在内核模式下，这意味着它们对所有的系统资源都有完全的访问权限。
- **异常处理程序一部分由硬件实现，另一部分由软件(操作系统)实现**
### 1.3 异常分类
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311231955962.png)
#### 同步和异步
- 同步：由于执行某条指令而发生的：系统调用，除零错误，机器检查等
- 异步：不是由于访问某条指令而产生的，发生的时间不可确定：键盘的Crtl+C,DMA等
#### 1.3.1 中断
- 异步
- I/O设备的信号的结果
- 硬件中断的处理程序称为**中断处理程序**
- 过程：
	- 中断引脚电压变高
	- 处理器注意到，就调用中断处理程序
	- 处理程序返回后，将控制返回给下一条指令
#### 1.3.2 陷阱和系统调用
- 同步
- **有意**的异常，是执行一条指令的结果。
- 将控制返回到下一条指令
- 最主要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做**系统调用**
	- 比如read、fork、execve、exit等
	- 每个系统调用都有一个唯一的整数号，对应于一个到内核中**跳转表**(**系统调用表**)的偏移量。
	- **系统级函数**
	- 调用的参数都是通过**通用寄存器**而不是栈传递的。%rax包含系统调用号，最多包含%rdi %rsi %rdx %r10 %r8 %r96个参数（与过程调用%rcx区分）
	- 处理器提供了一条特殊的**syscall n**指令，用户程序想要请求服务n时，可以执行这条指令。
	- 从系统调用返回时，%rcx和%r11都会被破坏，%rax包含返回值
	- -4095到-1之间的负数返回值说明发生了错误，对应于负的errno
	- 系统调用与普通函数调用的最大区别是：
		- 普通的函数运行在用户模式中；
		- 系统调用在**内核模式**中
			- 允许系统调用执行特权指令
			- 允许访问内核栈
	![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311232107957.png)

#### 1.3.3 故障
- 同步
- 错误情况引起
- 返回
	- 如果处理程序能够修正这个错误，就将控制返回到原指令，重新执行
	- 否则将回到内核中的abort例程，终止引起故障的程序
##### 常见错误
###### 除法错误
- **浮点异常Floating exception**
- 异常0
- 除以0或者除法指令的结果对于目标操作数来说太大。
- Linux选择直接终止程序
###### 一般保护故障
- 原因一般是
	- 引用了一个未定义的虚拟内存区域
	- 程序试图写一个只读的文本段
- **段故障Segmentation Fault**
###### 缺页
- 会重新执行产生故障的指令
- **Page Fault**
#### 1.3.4 终止
- 同步
- 不可恢复的致命错误造成的结果
- 通常是一些硬件错误，比如DRAM或SRAM被损坏时发生的奇偶错误。
- 控制返回abort，直接终止应用程序。
##### 机器检查
导致故障的指令中检测到致命的硬件错误时发生的，从不返回控制给应用程序
## 2.进程Process
### 2.1 关键抽象
- 一个独立的逻辑控制流：提供一个假象，好像我们的程序独占地使用处理器。
- 一个私有的地址空间：提供一个假象，好像我们的程序独占地使用内存系统。
### 2.2 概念剖析
#### 2.2.1 逻辑流
- PC值的序列叫做逻辑控制流
- **抢占preempted**：进程是轮流使用处理器的
#### 2.2.2 并发流与并行流
- 一个逻辑流的执行时间与另一个流重叠，成为**并发流concurrent flow**，这两个流称为并发地运行。这个思想与处理器核数或者计算机数无关。
- 如果两个流并发地运行在不同处理器核或计算机上，称为**并行流parrelel flow**。
#### 2.2.3 多任务和时间片
- 一个进程和其他进程轮流运行叫做**多任务**
- 一个进程执行它的控制流的一部分的每一时间段叫做**时间片**
- 多任务也叫时间分片
#### 2.2.4 私有地址空间
- 在一个n位地址的机器上，**地址空间**是$2^n$个可能地址的集合。
- 进程为每个地址提供它自己的**私有地址空间**
- 每个空间都有相同的通用结构：
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311232157404.png)
#### 2.2.5 用户模式和内核模式
- **模式位**
	- 设置模式位时，进程运行在内核模式(超级用户模式)
	- 否则运行在用户模式
		- 不允许执行**特权指令**
			- 停止处理器
			- 改变模式位
			- 发起一个I/O操作
		- 不允许用户模式中的进程直接引用地址空间中内核区的代码和数据
		- 通过系统调用间接访问
- /proc文件系统
	- 允许用户模式进程访问内核数据结构的内容
#### 2.2.6 上下文切换
- **上下文context**：内核重新启动一个被抢占的进程所需的状态
	- 由一些对象的值组成，包括：
		- 通用目的寄存器
		- 浮点寄存器
		- 程序计数器
		- 用户栈
		- 状态寄存器
		- 内核栈
		- 各种内核数据结构（页表、进程表、文件表等）
- **调度scheduling**：内核中的**调度器**处理。当内核选择一个新的进程运行，我们说内核**调度**了这个进程，它**抢占**当前进程。
- **上下文切换**来将控制转移到新的进程：
	- 保存当前进程的上下文
	- 恢复某个先前被抢占的进程被保存的上下文
	- 将控制传递给这个新恢复的进程
- 可能引发上下文切换的例子
	- ==系统调用==：如果因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，而切换另一个进程：
		- read系统调用需要访问磁盘
		- sleep系统调用显式请求调用系统休眠
	- ==中断==：定时器、DMA等
#### 2.2.7 系统调用错误处理
**错误处理包装函数**
### 2.3 进程控制
#### 2.3.1 获取进程ID
- getpid：返回调用进程的PID(每个进程都一个一个唯一的**正数非零PID**)
- getppid：返回父进程的PID
#### 2.3.2 创建和终止进程
##### 进程状态
- 运行
	- 在CPU上执行
	- 在等待被执行且最终会被内核调度
- 停止
	- 被挂起(suspended)，且不会被调度。
	- 当收到SIGSTOP/SIGTSTP/SIGTTIN/SIGTTOU信号时，进程就停止，并保持停止直到收到SIGCONT信号
- 终止（3种情况）
	- 收到一个信号，该信号的默认行为是终止进程
	- 从主程序返回
	- 调用exit函数
##### exit函数
- void exit(int status)；
- 以status**退出状态**来终止进程
##### fork函数
- `pid_t fork(void)`
- 子进程返回0，父进程返回子进程的PID，如果出错返回-1
- **调用一次，返回两次**
- **并发执行**
- **相同但是独立的地址空间**
- **共享文件**：子进程继承了父进程的所有打开文件
- 作图：拓扑排序为可行的全序排列
#### 2.3.3 回收子进程
- **wait_pid函数**，返回值：
	- 如果成功返回子进程的PID
	- 如果WNOHANG，返回0
	- 其他错误返回-1
- **回收reaped**
- **僵死进程zombie**
	- 如果一个父进程终止了，内核会安排init进程成为它的孤儿进程的养父。init进程：
		- PID为1
		- 系统启动时内核创建
		- 不会终止，是所有进程的祖先
- `pid_t waitpid(pid_t pid,int *statusp,int options)`
- **非确定性**行为：子进程回收顺序不定
##### 1.判定等待集合的成员
- pid确定
	- pid>0：等待集合一个单独子进程，进程ID为pid
	- pid=-1：等待集合是父进程的所有子进程
##### 2.修改默认行为
- options设置：
	- WNOHANG：挂起调用进程，直到有子进程终止
	- WUNTRACED：只返回已终止的子进程
	- WCONTINUED
	- 三个选项可以组合起来
##### 3.检查已回收子进程的退出状态
- statusup若非空，则其指向的status会放置关于导致返回子进程的状态信息，有几个宏：
	- WIFEXITED：如果子进程调用exit或return正常终止，则为真
	- WEXITSTATUS：返回正常终止的子进程的退出状态，只有WIFEXITED为真时才定义
	- WIFSIGNALED：如果是由于未被捕获的信号终止的，返回真
	- WTERMSIG：返回导致子进程终止的信号的编号
	- WIFSTOPPED：如果引起返回的子进程是停止的，返回真
	- WSTOPSIG：返回引起子进程停止的信号的编号
	- WIFCONTINUED：如果子进程收到SIGCONT信号重启，则返回真
##### 4.错误条件
- 如果没有子进程，那么返回-1，errno设置为ECHILD
- 如果被一个信号中断，那么返回-1，errno设置为EINTR
##### 5.wait函数
- waitpid函数的简化版本，wait(&status)等价于waitpid(-1,&status,0)
#### 2.3.4 让进程休眠
##### sleep函数
- 将一个进程挂起一段指定的时间
- 如果请求时间量已经达到，返回0，否则返回还剩下的要休眠的秒数。
##### pause函数
- 让调用函数休眠，直到该进程收到一个信号。
#### 2.3.5 加载并运行程序
- `int execve(const char *filename,const char *argv[],const char *envp[])`
##### 参数
- **调用一次从不返回**，加载并执行可执行目标文件filename
- argv变量指向一个以null结尾的指针数组，期中每个指针都指向一个参数字符串。argv\[0]是可执行目标文件的名字。
- envp变量指向一个以null结尾的指针数组，其中每个指针指向一个环境变量字符串，每个串都是"**name\==value**"的名字-值对。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311241953130.png)

##### main函数
- 传递给主函数：`int main(int argc,char **argv[],char **envp)`
- 用户栈的组织结构，栈底到栈顶依次是
	- 参数和环境字符串
	- envp数组，全局变量environ指向envp\[0]
	- argv数组
	- 栈的顶部是系统启动函数libc_start_main的栈帧
	- main的未来的栈帧
- 3个参数
	- argc给出argv\[]数组中非空指针的数量
	- argv，指向argv\[]数组中的第一个条目
	- envp，指向envp\[]数组中的第一个条目
##### 环境数组相关函数
- `char *getenv(const char *name)`
	- 在环境数组中搜索字符串name=value。如果找到，返回指向value的指针；
	- 否则返回NULL
- `int setenv(const char *name,const char *newvalue,int overwrite)`
	- overwrite非零时，用newvalue替代oldvalue
	- 当oldvalue不存在，把name=newvalue添加到数组中
- `void unsetenv(const char *name)`
	- 若存在name=oldvalue的字符串，unsetenv会删除它
#### 2.3.6 fork与execve
##### 对比
- 进程与程序
	- 进程是执行中程序的一个具体的示例
	- 程序总是运行在某个进程的上下文中。
- fork与execve
	- fork在新的子进程中运行相同的程序，新的子进程是父进程的一个复制品
	- execve在当前进程的上下文中加载并运行一个新进程，但没有创建一个新进程。新的程序仍然有相同的PID，并且继承了调用execve函数时已打开的所有文件描述符。
##### 利用fork和execve运行程序
- 编写一个简单的shell
	- sh csh tcsh ksh bash
	- 打印一个命令行提示符，等待用户在stdin上输入命令行，然后对这个命令行求值。
- 调用parseline函数`int parseline(char *buf,char **argv);`，解析以空格分隔的命令行参数，并构造最终会传递给execve的argv向量
	- 第一个参数
		- 被假设为一个内置的shell命令名，马上会解释这个命令
		- 否则是一个可执行目标文件，会在新的子进程中价值并运行
	- 最后一个参数
		- 如果是&，那么返回1，表示在**后台**执行
			- shell返回到循环顶部，等待下一个命令行
		- 否则返回0，表示在**前台**执行
			- shell使用waitpid函数等待作业终止，之后进行下一轮迭代
- `eval(char *cmdline)`调用`int builtin_command(char **argv)`函数，检查第一个命令行参数是否是一个内置的shell命令。
	- 如果是，立即执行，返回1
	- 否则返回0
		- 如果builtin_command返回0，那么shell创建一个子进程，并在子进程中执行所请求的程序
- 简单的shell只有一个内置命令-quit
## 3.信号Signal
### 3.1 引入
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311242024522.png)
一条信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。
- 常用信号：
	- 2 SIGINT 终止 对应Ctrl+C
	- 4 SIGILL 终止 对应非法事件
	- 8 SIGFPE 终止并转储内存 浮点异常
	- 9 SIGKILL 终止 对应终止程序
	- 11 SIGSEGV 终止且Dump 对应段冲突
	- 14 SIGALRM 终止 对应时间信号
	- 17 SIGCHLD 忽略 对应子进程终止或停止
- 进程收到信号-把信号交给**信号处理器signal handler**-返回下一条指令
- 信号术语
	- 发送信号，有两个原因
		- 内核检测到一个系统事件，比如除零错误或者子进程终止
		- 一个进程调用了kill函数，显示地要求内核发送一个信号给目的进程
	- 接收信号
		- 可以忽略
		- 可以终止
		- 也可以通过执行**信号处理程序**来**捕获**这个信号
	- 待处理信号：发出而没有被接收的信号
		- 如果k信号待处理(设置了pending中的第k位)，那么接下来发送到进程的k信号都不会排队等待，而是被丢弃；
		- **等待pending**
		- **阻塞blocked**
### 3.2 发送信号
#### 3.2.1 进程组process group
- 每个进程都只属于一个**进程组**，进程组由一个正整数进程组ID来标识
- `getpgrp()`返回当前进程的进程组ID
- `setpgid(pid_t pid,pid_t pgid)`改变自己或其他进程的进程组
	- 将进程pid的进程组改为pgid
	- 如果pid为0，就使用当前进程的PID
	- 如果pgid为0，就使用pid指定的进程的PID作为进程组ID
- 默认一个子进程和它的父进程属于同一个**进程组**
#### 3.2.2 用/bin/kill程序发送信号
- 可以向另外的进程发送任意信号
- 一个为负的PID会导致信号被发送到进程组PID中的每个进程
#### 3.2.3 从键盘发送信号
##### job
- shell使用**作业job**这个抽象概念表示为对一条命令行求值而创建的进程。**至多有一个前台作业和0个或多个后台作业**。
- shell为每个job创建一个独立的进程组，进程组ID通常取自job中父进程的一个。
##### 键盘
- Ctrl+C :SIGINT信号到前台进程组中的每个进程。
- Ctrl+Z:SIGTSTP信号到前台进程组的每个进程
#### 3.2.4 用kill函数发生信号
- `int kill(pid_t pid,int sig)`
- pid>0：kill发送信号sig给进程pid
- pid=0：kill发送信号sig给调用进程所在进程组中的每个进程，包括**调用进程自己**
- pid<0：kill发送信号sig给进程组|PID|中的每个进程。
#### 3.2.5 alarm函数发送信号
- `unsigned int alarm(unsigned int secs)`
- 内核在secs秒后发送一个SIGALRM信号给调用进程。
	- 如果secs是0，则不会安排新的闹钟
- 对alarm的调用将取消任何待处理的(pending)闹钟，并返回任何待处理的闹钟在被发送前还剩下的秒数
	- 如果没有待处理的闹钟，则返回0
### 3.3 接收信号
#### 基本逻辑
- 当进程p从内核模式切换到用户模式时，内核检查未阻塞的待处理信号的集合(pending&~blocked)。
	- 如果集合为空，控制转移到$I_{next}$；
	- 如果非空，内核选择集合中的某个信号k，并且强制p接收信号k。
		- 触发进程采取某种行为，一旦进程完成这个行为，会返回$I_{next}$
- 每个信号类型都有一定预定义的**默认**行为
	- 进程终止
	- 进程终止并转储内存
	- 进程停止(挂起)直到被SIGCONT信号重启
	- 进程忽略该信号
#### 设置信号处理程序 installing the handler
- `signal(int signum,sighandler_t handler);`函数修改与信号关联的默认行为
	- ==SIGSTOP和SIGKILL默认行为不能修改==
- 通过三种方法修改与signum相关联的行为
	- handler是SIG_IGN：忽略signum信号
	- handler是SIG_DFL：恢复为默认行为
	- 否则，handler就是用户定义的**信号处理程序**(一种函数)的地址。只要收到signum信号，就会调用这个程序
		- 调用信号处理程序叫做**捕获信号**
		- 执行信号处理程序叫做**处理信号**
		- 信号处理器也可以被其他信号处理器中断
### 3.4 阻塞和解除阻塞信号
#### 隐式阻塞机制
内核默认阻塞任何当前处理程序正在处理信号类型的待处理的信号。
#### 显式阻塞机制
- `sigprocmask(int how,const sigset_t *set,sigset_t *oldset)`
	- 改变阻塞的信号集合，具体行为依赖于how：
		- SIG_BLOCK:b把set中的信号添加到blocked中
		- SIG_UNBLOCK：从blocked中删除set中的信号
		- SIG_SETMASK：block=set
	- 如果oldset非空，blocked位向量之前的值保存在oldset中
- `sigfillset(sigset_t *set)`把所有信号添加到set中
- `sigemptyset(sigset_t *set)`创建空集
- `sigaddset(sigset *set,int signum)`添加制定信号到集合
- `sigdelset(const sigset *set,int signum)`删除集合中的制定信号
### 3.5 编写信号处理程序
#### 3.5.1 难点
1. 处理程序与主程序并发运行，可能与主程序和其他处理程序互相干扰。
2. 如何以及何时接收信号的规则常常有违人的直觉。
3. 不同的系统有不同的信号处理语义
#### 3.5.2 安全的信号处理
- 规则 1：信号处理器越简单越好
    - 例如：设置一个全局的标记，并返回
- 规则 2：信号处理器中只调用异步且信号安全(async-signal-safe)的函数
	- 原因有2
		- 它的所有变量都保存在栈帧中，是是**可重入**的
		- 它不能被信号处理程序中断
	- 诸如 `printf`, `sprintf`, `malloc` 和 `exit` 都是不安全的！(输出的唯一安全方法是write函数)
	- 开发了安全函数SIO
		- sio_putl和sio_puts函数分别向标准输出传送一个long类型数和一个字符串
		- sio_error函数打印一条错误信息并终止
- 规则 3：在进入和退出的时候保存和恢复 `errno`，在进入处理程序时把errno保存在一个局部变量中
    - 这样信号处理器就不会覆盖原有的 `errno` 值
- 规则 4：临时阻塞所有的信号以保证对于**共享数据结构**的访问
    - 防止可能出现的数据损坏
- 规则 5：用 `volatile` 关键字声明全局变量
    - 这样编译器就不会把它们保存在寄存器中，保证一致性
- 规则 6：用 `volatile sig_atomic_t` 来声明全局标识符(flag)
    - 这样可以防止出现访问异常
    - 这里对原子性的保证只适用于单个的读和写
#### 3.5.3 正确的信号处理
- 关键：如果存在一个未处理的信号就表明**至少**有一个信号到达了。
	- (见CSAPP上示例)
- 重要教训：**不可以用信号来对其他进程中发生的事件计数**。
#### 3.5.4 可移植的信号处理
- 不同的系统有不同的信号处理语义
	- signal函数的语义各有不同
	- 系统调用可以被中断。read/write/accept这样的系统调用潜在地会阻塞进程一段较长的时间，成为**慢速系统调用**。
- 定义了`sigaction(int signum,struct sigaction *act,struct sigaction *oldsact)`函数
	- 成功返回0，出错返回-1
	- 更简洁即为signal的包装函数Signal()
### 3.6 同步流以避免讨厌的并发错误
- 见CSAPP上的举例
- 保证父进程在相应的deletejob之前执行addjob
	- 当父进程创建一个新的子进程后，它就把这个子进程添加到作业列表中。
	- 当父进程在SIGCHLD处理程序中回收一个终止的子进程时，它就从作业列表中删除这个子进程。
	- 使用sigprocmask函数来同步进程，先阻塞SIG_CHLD信号直到addjob之后
### 3.7 显式地等待信号
- 见CSAPP详细举例
	- pause插入循环体
	- sleep代替pause
	- 合理的方法是使用`sigsuspend(const sigset_t *mask)`
		- 暂时用mask替换当前的阻塞集合，然后挂起该进程，直到收到一个信号
			- 运行一个处理程序：sigsuspend从处理程序返回，恢复调用sigsuspend时原有的阻塞集合。
			- 或终止该进程：进程直接终止
		- 这个函数的原子属性相当于保证sigprocmask和pause一起发生，即调用sigpromask之后在调用pause之前收到一个信号。
		- 它避免了引入pause带来的竞争，又比sleep更有效率
## 4.非本地跳转 Nonlocal Jumps
- 将控制直接从一个函数转移到另一个正在执行的函数，而不需要经过正常的调用-返回序列
- `int setjmp(jmp_buf env)`
	- env缓冲区中保存当前**调用环境**，返回0
	- 调用环境包括程序计数器、栈指针和通用目的寄存器
	- 返回值不能赋值给变量，但可以安全用在switch或条件语句的测试中
	- `int sigsetjmp(sigjmp_buf env,int savesigs)`
	- **只被调用一次，但返回多次**
- `void longjmp(jmp_buf env,int retval)`
	- 从env缓冲区中恢复调用环境，然后触发一个最近一次初始化env的setjmp调用的返回。然后setjmp返回，并带有非零的返回值retval
	- retval不可为0
	- **被调用一次，从不返回**
- 重要应用
	- 允许从一个深层嵌套的函数调用中立刻返回
	- 使一个信号处理程序分支到一个特殊的代码位置，而不是返回到被信号到达中断了的指令的位置。
## 5.操作进程的工具
- STRACE
- PS
- TOP
- PMAP
- /proc
# 第十章.系统级I/O
## 1.Unix I/O
- 一个Linux文件就是一个m个字节的序列：
	- B0,B1,..,Bk,...,Bm-1
- 所有的I/O设备都被模型化为**文件**，这允许Linux内核引出一个简单、低级的应用接口，成为Unix I/O。
	- 打开文件：
		- 内核打开相应文件，宣告想要访问一个I/O设备
		- 内核返回一个小的非负整数：**描述符**，它在后续对此文件的所有操作中标识这个文件。
	- Linux shell创建的每个进程开始时都有三个打开的文件：
		- **标准输入**：描述符0
		- **标准输出**：描述符1
		- **标准错误**：描述符2
		- 头文件`<unistd.h>`定义了常量STDIN_FILENO,STDOUT_FILENO,STDERR_FILENO，它们可以用来代替显示的描述符值。
	- 改变当前的文件位置
		- 对于每个打开的文件，内核保持着一个**文件位置k**，初始为0。这个文件位置是从文件开头起始的字节偏移量
		- 应用程序能够通过执行seek操作，显式地设置文件的当前位置为k
	- 读写文件：
		- 读操作：从文件复制n>0个字节到内存，从当前文件位置k开始，然后将k增加到k+n。如果k>=m(文件大小)，会触发EOF条件。
		- 写：从内存复制n>0个字节，从当前文件位置k开始更新。
	- 关闭文件
## 2.文件
### 类型(type)
- 普通文件regular file：
	- text file：
		- 只含有ASCII和Unicode字符的普通文件
		- 包含了text line序列，每一行都是一个字符序列，以**新行符\\n**结束。新行符ASCII码为0x0a
	- binary file：所有其他文件
- 目录directory
	- 包含一组**链接link**，每个链接都将一个filename映射到一个文件
	- 至少含有两个条目：
		- '.'是到该目录自身的链接
		- '..'是到目录层次结构中**父目录parent dictionary**的链接
		- makedir创建目录，ls查看内容，rmdir删除该目录
- 套接字socket：与另一个进程进行跨网络通信
- 命名通道named pipe
- 符号链接symbolic link
- 字符和块设备character and block device
### 目录层次结构directory hierarchy
- 名为\/的**根目录**确定
- 当前工作目录：可以用cd修改
- 路径名pathname
	- absolute pathname：一个斜杠开始，表示从根结点开始的路径
	- relative pathname：表示从当前工作目录开始的路径
## 3.打开和关闭文件
### 打开
- `int open(char *filename,int flags,mode_t mode)*`
- 将filename转换为1个文件描述符，并返回描述符数字。
- flags参数表明如何访问
	- O_RDONLY:只读
	- O_WRONLY:只写
	- O_RDWR:可读可写
	- 其他掩码的或：
		- O_CREAT:如果文件不存在，就创建它的一个**截断的(tuncated)** 空文件
		- O_TRUNC:如果文件已经存在，就截断它
		- O_APPEND:每次写操作之前，设置文件位置到文件的结尾处。
- mode参数指定新文件的访问权限位。位的符号名字见图
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311271846581.png)
- 每个进程都有一个umask，进程open函数调用时，访问权限位被设置为mode&umask。
### 关闭
- `int close(int fd)`关闭
## 4.读和写文件
### 读
- `ssize_t read(int fd,void *buf,size_t n)；`
- 若成功返回读的字节数；若EOF返回0；出错返回-1
- 表示从描述符为fd的**当前文件位置**复制最多n个字节到内存位置buf
### 写
- `ssize_t write(int fd,const void *buf,size_t n);`
- 返回：
	- 若成功返回写的字节数
	- 出错则为-1
### lseek函数
- 该函数能够显式地修改当前文件的位置。
### 不足值short count
#### 对比
- size_t:unsigned long
- ssize_t:long，有符号
#### 不足值
- read和write传送的字节比应用程序要求的要少
- 出现这种情况的原因
	- 读时遇到EOF
	- 从终端读取文本行
	- 读和写网络套接字
- 不会出现不足值的情况：
	- 读磁盘文件
	- 写磁盘文件
## 5.读取文件元数据
- **元数据metadata**：关于文件的信息
	- stat数据结构含有多个成员
```c++
struct stat
{
    dev_t           st_dev;     // Device
    ino_t           st_ino;     // inode
    mode_t          st_mode;    // Protection & file type
    nlink_t         st_nlink;   // Number of hard links
    uid_t           st_uid;     // User ID of owner
    gid_t           st_gid;     // Group ID of owner
    dev_t           st_rdev;    // Device type (if inode device)
    off_t           st_size;    // Total size, in bytes
    unsigned long   st_blksize; // Blocksize for filesystem I/O
    unsigned long   st_blocks;  // Number of blocks allocated
    time_t          st_atime;   // Time of last access
    time_t          st_mtime;   // Time of last modification
    time_t          st_ctime;   // Time of last change
}
```
- 常访问项：
	- st_size:文件的字节数大小
	- st_mode:文件访问许可位，sys/stat.h中定义了宏谓词来确定
		- S_ISREG(m):普通文件吗？
		- S_ISDIR(m):目录文件吗？
		- S_ISSOCK(m):网络套接字吗？
- `int stat(const char *filename,struct stat *buf)`
	- 以文件名为输入，检索信息
- `int fstat(int fd,struct stat *buf)`
	- 以文件描述符为输入，检索信息
## 6.读取目录和内容
- `DIR *opendir(const char *name)`
	- 以路径名为参数，返回指向**目录流directory stream**的指针
	- 出错返回NULL
- `struct dirent *readdir(DIR *dirp)`
	- 返回指向流dirp中下一个目录项的指针
	- 若没有更多目录项或出错，则返回NULL(出错会设置errno)
	- 区分错误和流结束：检查自调用readdir以来errno是否被修改过
- 每一个目录项都是一个结构
	- struct dirent{ ino_t d_ino; char d_name\[256];}(文件位置+文件名)
- `int closedir(DIR *dirp)`
	- 关闭流病释放所有资源
## 7.共享文件
- **内核用三个相关的数据结构表示打开的文件**
	- **描述符表descriptor table**:每个进程都有独立的描述符表，表项由进程打开的文件描述符来索引。每个打开的描述符表项指向**文件表**中一个表项。
		- 多个描述符也可以通过不同的文件表表项来引用同一个文件(比如open两次同一个文件) 
			- 指向文件表中不同文件
			- 但是文件A和B指向同一个v-node表，实际是同一个文件
			- 关键是每个描述符都有自己的文件位置，所以可以从文件的不同位置获取
	- **文件表file table**:打开文件的集合，所有进程共享这张表。表项组成包括
		- 当前文件位置k
		- **引用计数reference count**:描述进程引用数目的
			- 关闭一个描述符会减少相应的表项中的引用计数
			- 内核不会删除这个文件表表项，直到引用计数为0
		- 一个指向v-node表中对应表项的指针。
	- **v-node表**：所有进程共享，每个表包含stat结构中的大多数信息。
- 父进程和子进程共享相同的打开文件表集合，共享相同的文件位置。
## 8.I/O重定向
- `int dup2(int oldfd,int newfd);`
- dup2函数复制描述符表表项oldfd到newfd(覆盖)。如果newfd已经打开，dup2会在复制oldfd之前关闭newfd。
- 相当于将newfd本来指向的文件重定向到了oldfd对应的文件
## 9.Robust I/O(RIO)
### 9.1无缓冲的输入输出函数
- `ssize_t rio_readn(int fd,void *usrbuf,size_t n)`
- `ssize_t rio_writen(int fd,void *usrbuf,size_t n)`
	- 决不会返回不足值
### 9.2带缓冲的输入函数
- `ssize_t rio_readlineb(rio_t *rp,void *usrbuf,size_t maxlen)`
	- 从内部**读缓冲区**复制一个文本行
	- 当缓冲区变空时，会自动调用read重新填满缓冲区
	- 对于既包含文本行也包含二进制数据的文件，有rio_readn带缓冲区的版本。
- `ssize_t rioreadnb(rio_t *rp,void *usrbuf,size_t n)`
	- 从文件rp最多读n个字节到内存位置usrbuf
	- 对同一描述符，对rio_readlineb和rio_readnb的调用可以任意交叉进行。
- 带缓冲函数的调用不和无缓冲的rio_readn函数交叉使用
- 每次打开一个描述符，都会调用一次rio_readinitb函数，将描述符fd和地址rp处的一个类型为rio_t的读缓冲区联系起来。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202311271955837.png)
### 9.3 核心
- RIO读程序的核心是rio_read函数。
	- 当调用rio_read要求读n个字节
	- 读缓冲区内有rp->rio_cnt个未读字节
	- 如果缓冲区为空，会调用read填满它
	- 一旦缓冲区非空，rio_read就从缓冲区复制min{n,rp->rio_cnt}个字节到缓冲区，并返回复制的字节数
- rio_read函数与Linux read函数有相同的语义
## 10.Standard I/O
- C语言定义的标准I/O库
	- 打开fopen
	- 关闭fclose
	- 读字节fread
	- 写字节fwrite
	- 读字符串fgets
	- 写字符串fputs
	- 格式化函数scanf和printf
- 将打开的文件模型化为一个**流**。
	- 一个流就是一个指向FILE类型的结构的指针
	- 每个ANSIC程序开始时都有三个打开的流
		- stdin 标准输入
		- stdout 标准输出
		- stderr 标准错误
	- 类型为FILE的流是对文件描述符和**流缓冲区**的抽象
		- 使开销较高的Linux I/O系统调用的数量尽可能小。
## 11.使用哪种I/O函数
- Unix I/O (系统调用访问)
- Standard I/O
- Robust I/O
### 基本指导原则
- 只要有可能就使用标准I/O
- 不要使用scanf或rio_readlineb来读二进制文件
- 对网络套接字的I/O使用RIO函数，最好不要使用标准I/O函数(套接字使用lseek函数是非法的)
- 标准I/O函数的限制：
	- 跟在输出函数之后的输入函数：不能跟随，除非中间插入fflush/fseek/fsetpos/rewind
		- fflush:清空与流相关的缓冲区
		- 后三个函数使用Unix I/O lseek函数来重置当前的文件位置
	- 跟在输入函数之后的输出函数：不能跟随，除非中间插入fseek/fsetpos/rewind
# 第九章.虚拟内存
## 1.虚拟内存基础
### 1.1 基本概念
#### 1.1.1 从物理内存到虚拟内存
##### 物理地址Physical Address(PA)
- 计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。
- CPU访问内存的最自然的方式是使用物理地址
##### 虚拟地址Virtual Address(VA)
- CPU生成VA来访问主存，这个虚拟地址被**地址翻译**(address translation)为物理地址后传送到内存
- CPU芯片上叫做**内存管理单元Memory Management Unit,MMU**的专用硬件利用存放在主存中的查询表来动态翻译虚拟地址。
#### 1.1.2 地址空间address space
- **地址空间**是一个非负整数地址的有序集合{0,1,2,...}
	- 如果地址空间中整数连续，我们称其为一个**线性地址空间**(linear address space)
- 在一个带虚拟内存的系统重，CPU从一个有N=2^n个地址的地址空间中生成虚拟地址，这个地址空间成为**虚拟地址空间**(virtual address space){0,1,...N-1}.成为n位地址空间
	- 还有**物理地址空间**，对应物理内存的M个字节{0,1,2,...,M-1}.一般加上M=2^m
- 虚拟内存的基本思想：**允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间**。
### 1.2 虚拟内存作为工具
#### 1.2.1 虚拟内存作为缓存的工具
##### 基础逻辑
- VM系统通过将虚拟内存分割为成为**虚拟页**(Virtual Page,VP)的大小固定的块来处理这个问题。
	- 每个VP的大小为P=2^p字节
	- 类似地，物理内存被分割为**物理页**PP(又称**页帧page frame**)，大小也为P字节。
- 虚拟页面的集合被分割为三个不相交的子集
	- **未分配的**：VM系统还未分配（创建）的页，不占用任何磁盘空间
	- **缓存的**：当前已缓存在物理内存中的已分配页
	- **未缓存的**：未缓存在物理内存中的已分配页
- DRAM缓存的组织结构
	- 将使用SRAM缓存表示CPU和主存之间的L1,L2,L3高速缓存，使用DRAM缓存表示VM系统的缓存，它在主存中缓存虚拟页
	- DRAM缓存不命中要由磁盘服务，其不命中开销巨大，这驱动了其组织结构：
		- 虚拟页往往很大
		- 全相联，即任何虚拟页都可以放置在任何物理页中
		- 替换算法更加复杂精密(替换策略处罚也非常之高)
		- 总是使用写会而不是直写(因为对磁盘访问时间很长)
##### 页表
- 操作系统软件、MMU中的地址翻译硬件和存放在物理内存中的**页表page table**共同保证VM系统的缓存。
- 页表：
	- 将虚拟页映射到物理页。
		- 虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE。
	- 组织结构：
		- 一个**页表条目Page Table Entry，PTE**的数组。
		- 每个PTE由一个**有效位valid bit**和一个n位地址字段组成
			- 有效位表明该虚拟页是否被缓存在DRAM中
				- 如果设置有效位，地址字段就表示DRAM中相应的物理页的起始位置
				- 否则：
					- 为空地址，表示该虚拟页还未被分配
					- 否则指向该虚拟页在磁盘上的起始位置
		- 在DRAM中，每个进程都有自己的页表
##### 页命中Page Hit
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312041345329.png)
- 如果想要获取VP2中的虚拟内存的一个字：
	- 地址翻译硬件从内存中读取PTE3，根据有效位判断
	- 发现VP2已经被缓存在DRAM中
	- 这样直接从DRAM中读取
##### 缺页page fault
- 如果想要获取VP3中的虚拟内存的字：
	- VP3未缓存，不命中，触发**page fault**异常
	- 调用内核缺页异常程序
	- 选择一个**牺牲页**
	- 修改牺牲页的DRAM，把数据从磁盘复制过去
		- 复制过程中的等待时间为demand paging
		- 在磁盘和内存之间传送页(实际上就是**块**)的活动叫做**交换swapping**或者**页面调度paging**
			- 页从磁盘**换入/页面调入**DRAM和从DRAM**换出/页面调出**磁盘
			- 不命中发生时才换入页面的策略叫做**按需页面调度demand paging**
	- 重新执行访问指令，此时Page Hit
##### 分配
- 对于虚拟内存VPi,分配过程是在磁盘上创建空间并更新PTE5，使它指向磁盘上这个新创建的页面
##### 局部性利用
- 局部性locality保证了在任意时刻，程序将趋向于在一个较小的**活动页面active page**集合上工作，这个集合叫做**工作集working set**或**常驻集合resident set**
- 但是，如果工作集的大小超出了物理内存的大小，可能会发生**抖动thrashing**
#### 1.2.2 虚拟内存作为内存管理的工具
- 操作系统为每个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间
	- 多个虚拟页面可以映射到同一个共享物理页面上
- **简化链接**：内存映像基本格式的一致性极大简化了链接器的设计和实现
- **简化加载**：虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。
	- Linux加载器为.text和.data节分配虚拟页，把他们标记为无效的，将页表条目指向目标文件中适当的位置
	- 加载器从不从磁盘到内存实际复制任何数据
	- 将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作**内存映射memory mapping**
- **简化共享**：每个进程私有的内容，一般会由操作系统创建页表，将相应的虚拟页映射到不连续的物理页面
- **简化内存分配**：当1个运行在用户进程中的程序要求额外的堆空间（如调用malloc的结果）时，操作系统分配k个连续的虚拟内存页面，并且将它们映射到物理内存中任意k个位置的物理页面(**可以随机分散**)
#### 1.2.3 虚拟内存作为内存保护的工具
- 在每个PTE添加一些额外的许可位进行访问控制
	- SUP位表示进程是否必须运行在内核模式下才能访问该页
	- READ位控制对页面的读
	- WRITE位控制对页面的写
- 如果一条指令违反了这些许可条件，CPU会触发一个一般保护故障，一般称为**段错误segmentation fault**
### 1.3 地址翻译
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312041418344.png)
#### 1.3.1 翻译过程
- 形式上，地址翻译是一个N元素的VAS中元素和一个M元素的PAS中元素之间的映射：
	- MAP:VAS->PAS∪∅
- CPU中的一个控制寄存器：**页表基址寄存器Page Table Base Register,PTBR**指向当前页表
	- n位虚拟地址包含两部分：p位的**虚拟页面偏移Virtual Page Offset,VPO**和一个n-p位的**虚拟页号Virtual Page Number,VPN**
	- MMU利用VPN选择适当的PTE
	- 页表条目中的**物理页号Physical Page Number,PPN**和虚拟地址中的VPO串联起来，就得到相应物理地址。也即**物理页面偏移Physical Page Offset**和VPO是相同的
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312041427884.png)

##### 页命中
1. 处理器生成一个虚拟地址，并传送给MMU
2. MMU生成PTE地址，并从高速缓存/主存请求得到它
3. 高速缓存/主存向MMU返回PTE
4. MMU构造物理地址，并把它传送给高速缓存/主存
5. 高速缓存/主存返回所请求的数据字给处理器
##### 缺页
1. 处理器生成一个虚拟地址，并传送给MMU
2. MMU生成PTE地址，并从高速缓存/主存请求得到它
3. 高速缓存/主存向MMU返回PTE
4. PTE中有效位为0，MMU触发缺页异常处理程序
5. 缺页异常处理程序确定物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘
6. 缺页处理程序页面调入新的页面，并更新内存中的PTE
7. 缺页处理程序返回到原来的进程，在此执行导致缺页的指令，重复[[#页命中]].
#### 1.3.2 结合高速缓存和虚拟内存
- 一般利用物理寻址访问SRAM高速缓存
- 利用虚拟寻址访问DRAM缓存
- 结合思路：**地址翻译发生在高速缓存查找之前**
	- 页表条目可以缓存，就像其他数据字一样
#### 1.3.3 TLB加速地址翻译
- MMU中有一个关于PTE的小的缓存：**翻译后备缓冲器Translation Lookaside Buffer,TLB**
- TLB:直接分成两部分就可以，没有block的偏移位了(因为1个块只存储1个，不需要记录偏移量)
	- **VPN**
		- **索引TLBI**:VPN的t个最低位组成
		- **标记TLBT**：VPN中剩余的位组成
	- **VPO**
##### 过程
1. CPU产生虚拟地址
2. MMU从TLB中取出相应的PTE
	1. TLB命中：直接取出
	2. TLB不命中：MMU必须从L1缓存中取出想要的PTE。新取出的PTE存放在TLB中，可能会覆盖一个已经存在的条目
3. MMU将这个虚拟地址翻译成一个物理地址，并将它发送到高速缓存/主存
4. 高速缓存/主存将所请求的数据字返回CPU
#### 1.3.4 多级页表
- 压缩页表：**使用层次结构的页表**
- 一级页表中的每个PTE负责映射虚拟地址空间中的一个4MB的**片chunk**。假设地址空间是4GB，那么1024个PTE就可以覆盖整个空间了。
- 如果片i中的每个页面都未被分配，那么一级PTEi就为空。如果至少有一个页是分配了的，那么一级PTEi就指向一个二级页表的基址。
- 从两个方面减少了内存要求
	- 如果一级页表中的一个PTE是空的，那么相应的二级页表就根本不会存在，这代表着巨大的潜在节约
	- 只有一级页表才需要总是在**主存**中，VMS可以在需要时创建、页面调入或调出二级页表，减少了主存压力。
- k级页表：虚拟地址被划分为k个VPN和1个VPO。
	- 每个VPNi都是一个到第i级页表的索引，VPNi存储的为**对应页表的偏移量**
	- 第j级页表中的每个PTE，都指向第j+1级的某个页表的基址
	- 第k级页表中每个PTE包含某个物理页面的PPN，或者一个磁盘块的地址。
		- 因此，在能够确定PPN前，MMU必须访问k个PTE
		- 对于只有一级的页表结构，PPO和VPO是相同的。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312071928245.png)

## 2.案例研究：Intel Core i7/Linux内存系统
### 2.1 Core i7内存系统
- **处理器封装processor package**包括四个核、一个大的所有核共享的L3高速缓存，以及一个DDR3内存控制器。
	- 每个核包含一个层次结构的TLB、一个层次结构的数据和指令高速缓存，以及一组快速的点到点链路
	- TLB是虚拟寻址的，是四路组相连的
	- L1、L2、L3、高速缓存是可以物理寻址的，块大小为64字节。L1、L2是8路组相联，L3是16路组相联
- 页大小可以在启动时被配置为4KB或4MB，Linux使用的是4KB的页。
### 2.2 Core i7地址翻译
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312041639303.png)
- 要求物理页表4KB对齐
	- 对于1-3级PTE，只有40位有效物理地址，剩下的前面补0后面补1，保持4KB对齐获取下一级PTE的地址
- 要求物理页4KB对齐
- ==每个页表只占1页==
- 采用==4级页表==
- 1-3级页表条目的内容和第4级页表条目有所区别
- PTE有3个权限位，控制对页的访问
	- R/W位确定页的内容是可以读写的还是只读的
	- U/S位确定是否能够在用户模式中访问该页
	- XD(禁止执行)位可以用来禁止从某些内存页取指令
- MMU翻译虚拟地址时，还会更新另外两个内核缺页处理程序会用到的位
	- 访问页时，会设置A位，称为**引用位**
	- 在对一个页进行了写之后，会设置D位，又称**修改位或脏位dirty bit**。这告诉内核在复制替换页之前是否必须写回牺牲页
- 内核通过调用一条特殊的内核模式指令来清除引用位或修改位
- 在实际硬件实现中允许==MMU将虚拟地址翻译为物理地址==和==将物理地址传送到L1高速缓存==这两个步骤重叠，加速了访问。
	- VPO和PPO的12位是相同的
	- 八路组相联和、物理寻址的L1高速缓存有64个组和64字节缓存块，即6个缓存偏移位和6 个索引位，恰好符合VPO部分
	- 当CPU需要翻译一个虚拟地址时，会==发送VPN到MMU，发送VPO到高速L1缓存==。这样当MMU从TLB得到PPN时，L1高速缓存已经利用VPO找到了相应的组了
### 2.3 Linux虚拟内存系统
- Linux为每个进程维护了一个单独的虚拟地址空间
- 内核虚拟内存包含内核中的代码和数据结构。其某些区域被映射到所有进程共享的物理页面，例如每个进程共享内核的代码和全局数据结构
#### 2.3.1 Linux虚拟内存区域
- Linux将虚拟内存组织成一些**区域area**的集合。一个区域就是已分配的虚拟内存的**连续片chunk**，这些页是以某种方式相关联的。
	- 例如，代码段、数据段、堆、共享库段、用户栈都是不同的区域
	- 区域允许虚拟地址空间有间隙。
	- 每个存在的虚拟页面都保存在某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用。
	- 内核不用记录那些不存在的虚拟页。
- 内核为每个进程维护一个单独的任务结构
	- 任务结构中的元素包含或者指向内核运行该进程所需要的所有信息(如PID、指向用户栈的指针、可执行目标文件的名字、PC等)
	- 任务结构的一个条目指向mm_struct，描述虚拟内存当前状态
		- pgd：指向第一级页表的基址，运行进程时存放在CR3控制寄存器中
		- mmap指向vm_area_structs的链表
			- vm_start：指向这个区域的起始处
			- vm_end：指向这个区域的结束处
			- vm_prot：描述这个区域内包含的所有页的读写许可权限
			- vm_flags：描述共享还是私有
			- vm_next：指向链表中下一个区域结构
#### 2.3.2 Linux缺页异常处理
- 虚拟地址A是合法的吗?
	- Linux建立了一棵树帮助搜索区域结构的链表
- 试图进行的内存访问是否合法？即，进程是否有读、写或者执行这个区域内页面的权限？
- 否则，缺页是由于对合法的虚拟地址进行合法的操作造成的。那么：
	- 选择一个牺牲页面，如果牺牲页面被修改过，就将它交换出去，换入新的页面并更新页表
	- 当缺页处理程序返回时，CPU重新启动指令
## 3.内存映射
### 3.1 基础
- Linux通过将一个虚拟内存区域与一个磁盘上的**对象object**关联起来，来初始化这个虚拟内存区域的内容，这个过程称为**内存映射memory mapping**.虚拟内存区域可以映射到两种类型的对象中的一种：
	- **Linux文件系统中的普通文件**：一个区域可以映射到一个普通磁盘文件的连续部分，比如可执行目标文件
		- 文件区(section)被分成页大小的片，每一片包含一个虚拟页面的初始内容
		- 这些虚拟页面没有实际交换进入物理内存，直到CPU第一次引用到页面(因为按需进行页面调度)
		- 如果区域比文件区要大，就用0来填充区域余下部分
	- **匿名文件**：匿名文件是由**内核**创建的，包含的全是二进制零。
		- CPU第一次引用这样一个区域的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面：如果被修改过就换出来，用**二进制零**覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。
		- 磁盘和内存之间没有实际的数据传送
		- 所以区域中的页面有时也叫做**请求二进制零的页deman-zero page**
- 一旦虚拟页面被初始化，就在一个由内核维护的专门的**交换文件swap file/交换空间swap space/交换区域swap area**之间换来换去。
	- 在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数
### 3.2 共享对象
- **共享对象**
	- 共享区域
	- 不同进程将共享对象映射到同一物理内存，物理内存只需存放一个副本
- **私有对象**
	- 私有区域
	- 采用**写时复制copy-on-write**的方式映射
		- 开始生命周期方式基本上与共享对象的一样，在物理内存中只保存着私有对象的一份副本。
		- 对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为**私有的写时复制**：只要进程没有试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。
		- 当有一个进程试图写时，会出发一个保护障碍
		- 故障处理程序在物理内存中创建新副本，更新页表条目指向页面的新副本，恢复页面可写权限
### 3.3 fork函数
- 当fork被==当前进程==调用时，内核为==新进程==创建各种数据结构，并分配给它一个唯一的PID
	- 创建当前进程的mm_struct、区域结构和页表的原样副本
	- 将两个进程的每个页面都标记为只读，以及标记私有的写时复制
- 从==新进程==中返回时，新进程现在的虚拟内存刚好和调用fork时存在的虚拟内存相同
### 3.4 execve函数
`execve("a.out",NULL,NULL);`加载并运行a.out需要以下几个步骤：
1. **删除已存在的用户区域**。
2. **映射私有区域**。为新程序的代码、数据、bss和栈区域创建新的区域结构(都是私有)
	1. 代码和数据区域被映射为a.out文件中的.text和.data区
	2. bss区域是**请求二进制零**的，初始长度为0
3. **映射共享区域**。动态链接共享对象
4. **设置程序计数器PC**，使之指向代码区域的入口点。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312041927996.png)
### 3.5 使用mmap函数的用户级内存映射
- `void *mmap(void *start,size_t length,int prot,int flags,int fd,off_t  offset)`
	- 要求内核创建一个新的虚拟内存区域
	- 最好从start开始(通常被定义为NULL)
	- 将文件描述符fd指定的对象的一个连续的片(chunk)映射到这个区域
		- **连续的片**大小为length字节
		- 从距文件开始处偏移量为offset字节的地方开始
	- 参数prot包含描述新映射的虚拟内存区域的访问权限位(即vm_prot位)
		- PROT_EXEC：可以被CPU执行的指令组成
		- PROT_READ：可读
		- PROT_WRITE：可写
		- PROT_NONE：不能被访问
	- 参数flags由描述被映射对象类型的位组成
		- MAP_ANON标记位：==匿名对象==，想要的虚拟页面是==请求二进制零==的
		- MAP_PRIVATE：私有的、写时复制的对象
		- MAP_SHARED：是一个共享对象
- `int munmap(void *start,size_t length)`
	- 删除虚拟内存的区域
	- 从虚拟地址start开始
	- 由接下来length字节组成
## 4.动态分配内存
### 4.1 概念
- **动态内存分配器dynamic memory allocator**：运行需要额外虚拟内存时使用，具有更好的可移植性
	- 维护者一个进程的虚拟内存区域-**堆heap**
		- 对于每个进程，内核维护着一个变量brk，指向堆的顶部
		- 堆向上生长(更高的地址)
	- 分配器将堆视为一组不同大小的**块block**的集合来维护每个块就是一个连续的虚拟内存片(chunk)：
		- 已分配：显式地保留供应用程序使用
		- 空闲的：保持空闲，直到显式分配
	- 两种基本风格
		- **显式分配器explicit allocator**：应用显式地释放任何已分配的块
		- **隐式分配器implicit allocator**：要求分配器检测一个已分配块何时不再被程序所使用，然后释放这个块
			- 也叫**垃圾收集器garbage collector**
			- 自动释放的过程叫做**垃圾收集garbage collection**
### 4.2 显式分配器
#### 4.2.1 知识储备
##### 1.malloc和free函数
- `void *malloc(size_t size);`
	- 返回一个指针，指向大小至少为siez字节的内存块(会为可能包含在这个块内的任何数据对象类型做**对齐**)
		- 32位：malloc返回的块的地址总是8的倍数
		- 64位：malloc返回的块的地址总是16的倍数
	- 遇到问题返回NULL并设置errno
	- 不初始化它返回的内存
		- calloc包装函数将分配的内存初始化为0
		- realloc函数改变一个已分配块的大小
- `void *sbrk(intptr_t incr);`
	- 将内核的brk(指向堆顶)指针增加incr来扩展或收缩堆
	- 成功返回brk旧值；否则返回-1并将errno设置为ENOMEM
	- incr=0:返回incr当前值
	- incr<0：返回值指向距新堆顶向上abs(incr)字节处
- `void free(void *ptr)`
	- ptr参数必须指向从malloc/calloc/realloc获得的已分配块的起始位置
##### 2.使用动态内存分配的原因
>经常直到程序实际运行时，才知道某些数据结构的大小

##### 3.分配器的要求和目标
###### 约束和限制条件
- 处理任意请求序列。分配器不可以假设分配和释放请求的顺序
- 立即响应请求。
- 只使用堆。
- 对齐块。
- 不修改已分配的块。
###### 目标性能
- **最大化吞吐率**
	- 吞吐率定义为每个单位时间里完成的请求数
	- 所谓合理性能是指一个分配请求的最槽运行时间与空闲块的数量成线性关系，而一个释放请求的运行时间是个常数。
- **最大化内存利用率**
	- 描述分配器使用堆的效率，最有用的标准：**Uk峰值利用率peak utilization**
		- ==payload有效载荷==
		- ==aggregate payload聚集有效载荷Pk==
		- Hk堆的当前大小
		- Uk=${max_{i<=k}Pi}/H_k$
	- 分配器的目标就是在整个序列中使峰值利用率Un-1最大化。
##### 4.碎片fragmentation
- **内部碎片internal fragmentation**
	- 已分配块比有效载荷大时发生的
	- 量化：已分配块大小和它们的有效载荷大小之差的和其数量只取决于
		- 以前请求的模式
		- 分配器的实现方式
- **外部碎片external fragmentation**
	- 空闲内存合计足够满足一个分配请求，但是没有一个单独的空闲块足够大来处理这个请求时发生
	- 量化困难，取决于
		- 以前请求的模式
		- 分配器的实现方式
		- **将来**请求的模式
#### 4.2.2 实现
##### 1.隐式空闲链表
- 实际的分配器需要一些数据结构
	- 允许它来
		- 区别块边界
		- 区别已分配块和空闲块
	- 块的简单实现
		- 一个字的**头部**，存放
			- 块大小
				- 如果强加一个双字的对齐约束，那么块大小就总是8的倍数
				- ==低三位==总是0
					- 00a，a=1表示已分配；a=0表示空闲
		- 有效载荷
		- 所有的**填充**
- 可以用**隐式空闲链表**来组织堆结构(组织为1个连续的已分配块和空闲块的序列)
	- 空闲块通过头部中的大小字段隐含地连接着
	- 分配器可以通过遍历堆中**所有**的块，从而间接地遍历整个空闲块的集合
	- 需要某种特殊标记的结束块。比如一个设置了已分配位而大小为0的**终止头部terminating header**
- 优缺点
	- 优点：简单
	- 缺点：任何操作的开销较大
- 重点：==系统对齐要求和分配器对块格式的选择会对分配器上的**最小块大小**有强制要求==
	- 没有已分配块或者空闲块可以比这个最小块大小值还小
##### 2.块处理
###### A.放置已分配的块
**放置策略placement policy**选择
- **首次适配first fit**
	- 从头开始搜索空闲链表，选择第一个合适的空闲块
	- 优点：趋向于将大的空闲块保留在链表的后面
	- 缺点：趋向于在靠近链表起始处留下小空闲块的“碎片”，增加了对较大块的搜索时间
- **下一次适配next fit**
	- 从上一次结束的地方开始查询
	- 但是内存利用率最低
- **最佳适配best fit**
	- 检查每个空闲块，选择适合所需请求大小的最小空闲块
###### B.分割空闲块
- 用整个空闲块
	- 会造成内部碎片
	- 如果趋向于产生好的匹配的话，可接受
- **分割**为两部分
	- 第一部分变成分配块
	- 剩下部分变成新的空闲块
###### C.合并空闲块
- 分配器释放一个分配块时，可能有其他空闲块与这个新释放的空闲块相邻，相邻空闲块可能引起**假碎片fault fragmentation**
	- 有许多可用的空闲块被分割成小的、无法使用的空闲块
- 解决：任何实际的分配器都必须**合并coalescing**相邻的空闲块
	- **立即合并immediate coalescing**
		- 可以常数时间内执行完成
		- 但对于某些请求模式，会产生一种形式的**抖动**：块会反复合并，然后马上分割
	- **推迟合并defferred coalescing**
###### D.带边界标记的合并
对于**当前块**
- 下一个块：直接检查指向下一个块头部的指针以判断下一个块是否空闲
- 前面的块：**边界标记boundary tag**
	- 允许在常数时间内进行对前面块的合并
	- 在每个块的结尾处添加一个**脚部footer**，是头部的一个副本
		- 分配器可以通过检查它的脚部，判断前面一个块的起始位置和状态。
		- 总是在距**当前块开始位置一个字**的距离
	- 缺陷：在应用程序操作多个小时后，产生显著的内存开销
- 改进：只有在前面的块是空闲时，才会需要用到它的脚部
	- 把前面块的已分配/空闲位存放在当前块中多出来的低位中
	- 那么已分配的块就不需要脚部了
	- 但是空闲块仍需要脚部
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312052108117.png)

##### 3.实现简单分配器(利用隐式空闲链表)
- 假设：
	- 使用立即边界标记合并方式
	- 最大的块大小为4GB
	- 代码是64位干净的
- 注意：***代码实现全部见CSAPP全书***
###### A.通用分配器设计
- **使用memlib.c包提供的模型**
	- 目的：允许在不干涉已存在的系统层malloc包的情况下，运行分配器
	- `mem_init()`函数：将虚拟内存模型化为一个大的、双字对齐的字节数组
	- `mem_heap`与mem_brk之间的字节表示已分配的内存
	- `mem_brk`之后的字节表示为分配的虚拟内存
	- `mem_sbrk`函数来请求额外的堆内存
	- 分配器包含在一个源文件mm.c中，输出三个函数到应用程序
		- `int mm_init(void)`函数
			- 成功返回0，否则返回-1
		- `void *mm_malloc(size_t size)`函数
		- `void mm_free(void *ptr)`函数
- 分配器使用块格式，最小块大小为16字节
- 空闲链表组织为一个隐式空闲链表
	- 第一个字是一个双字边界对齐的不使用的**填充字**
	- 填充后面紧跟着一个特殊的**序言块prologue block**
		- 1个8字节的已分配块
		- 只由头部和脚部组成
		- 初始化时创建，并且==永不释放==
	- 序言块后面是0个或多个由malloc或者free调用创建的**普通块**
	- 以一个特殊的**结尾块epilogue block**结束
		- 大小为0的已分配块
		- 只由一个头部组成
	- 序言块和结尾块是一种消除合并时边界条件的技巧
- 分配器使用一个单独的**私有全局变量heap_listp**，总是指向序言块
###### B.操作空闲链表的基本常数和宏
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312060958266.png)
- PACK将大小和已分配位结合起来并返回一个值，可以把它存放在头部或者脚部中
- GET读取和返回参数p引用的字
	- 强制类型转换至关重要
	- p是一个(void \*)指针，==不可以直接进行间接引用==
- PUT(p,val)将val存放在参数p指向的字中
- GET_SIZE和GET_ALLOC从p处头部或脚部分别返回大小和已分配位
- 对**块指针bp**的操作
	- HDRP：指向头部
	- FTRP：指向脚部
	- NEXT_BLKP：指向后面的块
	- PREV_BLKP：指向前面的块
###### C.创建初始空闲链表
- 先用mm_init函数初始化堆
	- 初始化，创建空的空闲链表
	- 调用extend_heap函数，将这个函数扩展CHUNKSIZE字节，并创建初始的空闲块.extend_heap函数：
		- 在两种不同环境中被调用
			- 堆被初始化时
			- mm_malloc不能找到一个合适的匹配块时，为了保持对齐，extend_heap请求大小向上舍入为最接近的2字的倍数，然后请求额外堆空间
		- 堆开始于一个双字对齐的边界，并且每次对extend_heap的调用都返回一个块(双字整数倍)。故对mem_sbrk的每次调用都返回一个双字对齐的内存片，紧跟在结尾块的头部后面
			- 这个头部变成了新的空闲块的头部
			- 这个片的最后一个字变成了新的结尾块的头部
			- (可能)用coalesce函数来合并空闲块，并返回指向合并后的块的块指针
###### D.释放和合并块
- 调用mm_free函数来释放一个以前分配的块(bp)
- 然后使用**边界标记合并技术**将之与邻接的空闲块合并起来(`static void *coalesce(void *bp)`函数)
###### E.分配块
- 调用mm_malloc函数向内存请求大小为size字节的块
	- 在检查完请求的真假后，分配块必须==调整请求块的大小==，为头部和脚部留有空间
	- 强制最小快大小为16字节：8字节满足对齐要求，另外8字节放头部和脚部
	- 对于超过8字节的请求，一般是加上开销字节，然后向上舍入到最接近8的整数倍
	- 分配器调整请求大小后，会搜索空闲链表，寻找合适空闲块
		- 如果合适，放置请求块，并可选地分割出多余的部分，返回新分配块的地址
		- 如果没有，就用新的空闲块来扩展堆，把请求块放置在这个新的空闲块里，可选地分割这个块；最后返回一个指针，指向这个新分配的块
##### 4.显式空闲链表
- 将空闲块组织为某种形式的显式数据结构
- 比如：使用双向空闲链表，每个空闲块中都包含一个**前驱pred**和**后继succ**指针
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312061337282.png)
- 这样可以
	- 使首次适配的分配时间从块总数的线性时间减少到了空闲块数量的线性时间
	- 释放一个块的时间取决于空闲链表中块的排序策略：
		- **LIFO(后进先出)**：新释放的块放置在链表的开始处
			- 使用LIFO+首次适配，会先检查最近使用过的块，这样可以在常数时间内完成释放一个块
		- **地址顺序**来维护链表
			- 每个块的地址都小于它后继的地址
			- 释放一个块需要线性时间的搜索来定位合适的前驱
			- 地址顺序+首次适配，拥有更高的==内存利用率==，接近最佳适配的利用率
- 缺点
	- 导致了更大的最小块大小
	- 潜在地提高了内部碎片的程度
##### 5.分离空闲链表
- 减少分配时间的方法：**分离存储segregated storage**
	- 思路：将所有可能的块大小分成一些等价类：**大小类size class**
	- 维护一个**空闲链表数组**：每个大小类一个空闲链表,安装大小的升序排列
###### A.简单分离存储simple segregated storage
- 每个大小类的空闲链表包含大小相等的块，每个块的大小就是这个大小类中最大元素的大小。
- 检查相应的空闲链表
	- 如果链表非空，简单地分配其中第一块的全部(空闲块是不会分割以满足分配请求的)
	- 如果链表为空，分配器就向操作系统请求一个固定大小的额外内存片(通常是页大小的整数倍)，将这个片分成大小相等的块，并链接起来形成新的空闲链表
- 释放一个块：将这个块插入到相应的空闲链表的前部
- 优点：
	- 都是很快的常数时间操作
	- 每个块不分割、不合并，意味着只有很小的内存开销
	- 链表只需单向
	- 关键：**任何块中都需要的唯一字段是每个空闲块中的一个字的succ指针**。因此最小块大小就是一个字
- 缺点
	- 容易造成内部和外部碎片
	- 因为不会合并空闲块，所以某些引用模式会引起极多的外部碎片
###### B.分离适配segregated fit
- 每个链表包含潜在的大小不同的块，这些块的大小是大小类的成员
- 分配一个块：
	- 确定请求的大小类，对适当的链表做首次适配，查找合适块
		- 如果找到，就(可选地)分割它，并将剩余的部分插入到适当的空闲链表中
		- 如果找不到，就搜索下一个更大的大小类空闲链表
		- 如果始终找不到，就向操作系统请求额外的堆内存，从新内存中分配出一个块，把剩余部分放在适当的大小类中
- 释放一个块：执行合并，将结果放置在相应空闲链表中
- 对分离空闲链表的首次适配搜索，其内存利用率已经近似于最佳适配搜索的内存利用率
###### C.伙伴系统buddy system
- 分类适配的一种特例：每个大小类都是2的幂
- 假设堆大小为$2^m$，为每个块大小$2^k$维护一个分离空闲链表(0<=k<=m)
	- 找到第一个可用的、大小为$2^j$的块(k<=j<=m)
		- 如果j=k，完成
		- 否则，递归地二分割这个块，直到j=k
			- 剩下的半块叫做**伙伴**,被放置在相应的空闲链表中
- 要释放一个大小为$2^k$的块，我们继续合并空闲的伙伴，直到遇到一个已分配的伙伴
- 给定地址和块的大小->很容易计算出它的伙伴的地址
- 优点：快速检索和快速合并
- 确定：可能导致显著的内部碎片，不适合通用目的的工作负载
### 4.3 隐式分配器(垃圾收集器)garbage collector
#### 4.3.1 基本知识
- 将内存视为一张**有向可达图rechability graph**，节点被分为一组**根节点root node**(根节点对应于一种不在堆中但是包含指向堆中的指针的位置)和一组**堆节点heap node**(对应与堆中的一个已分配块)
- 有向边p->q意味着块p中的某个位置指向块q中的某个位置
	- 当存在一条任意从根节点出发并到达p的有向路径时，说p是**可达的reachable**
	- 不可达节点对应垃圾，应被释放并返回给空闲链表
- 关键思想：收集器代替应用去调用free
#### 4.3.2 Mark&Sweep垃圾收集器
- **标记mark**阶段：标记出根结点的所有可达和已分配的后继
	- 为每个根结点调用一次mark函数
		- 如果p不指向一个已分配并且未标记的堆块，mark函数立即返回
		- 否则，标记这个块，并对块中每个字递归调用它自己
- **清除sweep**阶段：释放每个未被标记的已分配块
	- sweep函数在堆中每个块上反复循环，释放它所遇到的所有未标记的已分配块
- 函数，其中ptr定义为typedef void \*ptr;
	- `ptr isPtr(ptr p)`
	- `int blockMarked(ptr b)`
	- `int blockAllocated(ptr b)`
	- `void markBlock(ptr b)`
	- `int length(b)`
	- `void unmarkBlock(ptr b)`
	- `ptr(nextBlock(ptr b)`
#### 4.3.3 C程序的保守Mark&Sweep
##### 保守原因
- 其不能维护可达图的一种精确表示，这样的收集器叫做**保守的垃圾收集器conservative garbage collector**
- C语言为isPtr函数的实现造成了一些有趣的挑战
##### 挑战
- C不会用任何类型信息来标记内存位置。对isPtr没有一种明显的方式来判断它的输入参数p是不是一个指针
- 即使知道p是一个指针，对isPtr也没有明显方式来判断p是否指向一个已分配块的有效载荷中的某个位置
	- 解决：将已分配块集合维护成一棵==平衡二叉树==
		- 左子树的所有块都放在较小地址处，右子树的所有块都放在较大地址处
		- 要求每个已分配的头部里有两个附加字段left和right，每个字段指向某个已分配块的头部
		- isPtr用树来执行对已分配块的二分查找。在每一步中，它依赖于块头部的大小字段来判断p是否落在这个块的范围之内
## 5.内存常见错误
### 5.1 间接引用坏指针
- 虚拟地址空间中有较大的洞，如果试图间接引用一个指向这些洞的指针，会异常终止
- 虚拟内存某些区域只读，试图写这些区域将会以保护异常中止这个程序
- 错误：`scanf("%d",&val)`写成`scanf("%d",val)
### 5.2 读未初始化的内存
- 堆内存只调用malloc是不被初始化的
### 5.3 允许栈缓冲区溢出
**缓冲区溢出错误buffer overflow bug**
### 5.4 假设指针和它们指向的对象是相同大小的
**在远处起作用action at distance**错误的典型情况
### 5.5 造成错位错误
**错位off-by-one**-可能覆盖了后面的内存
### 5.6 引用指针，而不是它所指向的对象
如果不注意C操作符的优先级和结合性会导致的错误地操作指针而非指针所指向的对象
### 5.7 误解指针运算
**忘记了指针的算术操作是以它们指向的对象的大小为单位来进行的，而这种大小单位不一定是字节**
### 5.8 引用不存在的变量
比如p指向栈里的局部变量，在函数结束后p就不再指向合法变量了，再引用p会出现错误
### 5.9 引用空闲堆块中的数据
引用了已经被释放了的堆块中的数据
### 5.10 引起内存泄露
- 不小心忘记释放已分配块，而在堆里创建了垃圾
- 如果经常调用leak，渐渐堆里就会充满垃圾，糟糕时会占用整个虚拟地址空间
# 第十一章.网络编程
## 1.引入
### 1.1 客户端-服务端
- 每个网络应用都是基于**客户端-服务器**模型的。一个应用由==一个服务器进程和多个客户端进程==组成。服务器管理**资源**
- 模型基本操作是**事务transaction**，由以下四步组成
	- 客户端向服务器发送请求，发起一个事务
	- 服务器收到请求，解释，以适当方式操作资源
	- 服务器给客户端发送一个**响应**，并等待下一个请求
	- 客户端收到响应并处理它
- 注意：**客户端和服务器都是进程**，不是所谓的机器或主机。一台主机可以同时运行不同的客户端和服务器
### 1.2  网络
- ==对主机而言==，网络只是一种I/O设备，是数据源和数据接收方
	- 一个插入到I/O总线扩展槽的==适配器==提供了到网络的物理接口
	- 从网络收到的数据从适配器经过I/O和内存总线复制到内存，通常是DMA传送
- ==物理意义而言==，网络是一个按照地理远近组成的层次系统
	- 最低层是==LAN(Local Area Network)局域网==
	- **以太网Ethernet**是最流行的局域网技术
		- 一个以太网段包括一些电缆和**集线器**
		- 每根电缆都有相同的**最大位带宽**，一端连接到主机的适配器，另一端连接到集线器的一个**端口**上
		- 集线器会把收到的位复制到其他所有端口
			- 每台主机都能看到每个位
			- 一台主机可以发送一段位(**帧frame**)到这个网段的其他任何主机
				- 每个帧包括固定数量的==头部位==，用来标识帧的源和目的地址以及此帧的长度
				- 此后紧随的是数据位的**有效载荷Payload**
	- 使用电缆+**网桥bridge**，多个以太网段连接成较大的局域网，称为**桥接以太网bridged Ethernet**
		- 电缆
			- 一些电缆连接网桥与网桥，另外一些连接网桥和集线器、
			- 这些电缆的带宽可以不同
		- 网桥自动学习主机可以通过哪个端口可达，有必要时才将帧从一个端口复制到另一个端口
			- 例：A发送帧到同网段的B，该帧到达网桥X时，X会直接丢弃该帧
			- 从而节省网段带宽
	- 多个不兼容的局域网由**路由器router**连接起来组成internet(互联网络)
		- 每台路由器到它所连接的每个网络都有适配器(端口)
		- 路由器可以连接高速点到点电话连接，称为==WAN Wide-Area-Network广域网==
		- 路由器用来由各种局域网和广域网构建互联网络
- 主机发送数据到主机，要跨越不兼容的网络发送数据位，解决：
	- 一层运行在每台主机和路由器上的**协议软件**，这个软件实现一种协议，提供：
		- **命名机制**：每台主机会被分配至少一个**互联网网络地址internet address**，这个地址唯一地标识了这台主机
		- **传送机制**：电缆上编码位和将数据位封装成==帧==，互联网协议把这些数据位**封装**不连续的片-**包**的统一方式消除差异，包的组成：
			- **包头**，包括包的大小以及源主机和目的主机的地址
			- **有效载荷**，包括从源主机发出的数据位
			- 示例：==主机上的协议软件通过在数据前附加互联网络包头和 LANI 帧头，创建了 LANI 的帧。互联网络包头寻址到互联网络主机 ,LANI 帧头寻址到路由器。然后它传送此帧到适配器 注意，LANI 帧的有效载荷是一个**互联网络包**，而互联网络包的有效载荷是实际的用户数据。这种**封装**是基本的网络互联方法之一==。
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312122200309.png)
## 2.全球IP因特网
- 每台因特网主机都运行实现**TCP/IP(Transmission Control Protocol/Internet Protocol)协议**
- 客户端和服务端混合使用**套接字接口**函数和Unix I/O函数来进行通信
- IP协议提供基本的命名方法和递送机制
	- 可以从一台因特网主机往其他主机发送包-**数据报datagram**
	- 不可靠：不会试图恢复丢失或重复的数据报->**UDP**
- 把因特网看做一个世界范围的主机集合
	- 主机集合被映射为一组32为的IP地址
	- 这组IP地址被映射为一组称为**因特网域名Internet domain nama**的标识符
	- 因特网主机上的进程能够通过**连接connection**和任何其他因特网主机上的进程通信
### 2.1 IP地址
- 一个32位无符号整数`struct in_addr{unit32_t s_addr;};`
- IP地址结构中地址以**网络字节顺序network byte order(大端)存放**
- **主机字节顺序host byte order(小端)**
- 有4个函数实现两种数据转换
	- htonl(unit32_t hostlong)：小端变大端 32位整数
	- htons(unit16_t hostshoret)：小端变大端 16位整数
	- ntohl(unit32_t netlong)：大端变小端 32位
	- ntohs(unit32_t netshort)：大端变小端 16位
- IP地址通常是以**点分十进制表示法**来表示的
	- 每个字节由它的十进制值表示，并且用句点和其他字节间分开
	- 使用HOSTNAME命令可以确定主机的点分十进制地址
	- 使用函数来进行IP地址和点分十进制串之间的转换(n代表网络，p代表表示)
		- `int inet_pton(AF_INET,const char*src,void *dst)`
			- 成功返回1
			- src为非法点分十进制地址则返回0
			- 出错返回-1，设置errno
			- AF_INET为32为IPv4地址
		- `const char *inet_ntop(AF_INET,const void *src,char *dst,socklen_t size)`
			- 成功返回指向点分十进制字符串的指针
			- 出错返回NULL
			- 把得到的null结尾的字符串最多复制size个字节到dst
### 2.2 因特网域名domain name
- 域名集合形成一个层次结构，编码在层次中的位置
- 可以表示为一棵树
	- 子树为子域(subdomain)
	- 第一层是未命名的根
	- 下一层是**一级域名first-level domain name**
	- 下一层是**二级域名second-level**
		- 由ICANN各个授权代理按照先到先服务的基础分配
- 因特网定义了域名集合和IP地址集合之间的映射，通过==DNS 域名系统==来维护
	- 由上百万条**主机条目结构host entry structure**组成，定义了一组映射
	- 每台因特网主机都有自己本地定义的域名localhost，总是映射为**回送地址loopback address**
	- 用HOSTNAME确定实际域名
- **一个或多个域名可以与一个或多个IP地址映射**
- **某些合法的域名可能没有映射到任何IP地址**
### 2.3 因特网连接
- 连接：**点对点**、**全双工**、**可靠**
- **套接字socket**是连接的一个端点，有相应的**套接字地址**，用"==地址：端口=="表示(端口为16位整数)
	- 客户端一般内核自动分配端口，为**临时端口ephemeral port**
	- 服务器一般是某**知名端口**，与服务器相对应
		- 每个知名端口的服务器都有一个对应的知名的服务名
- 一个连接由**套接字对socket pair**唯一确定
## 3.套接字接口socket interface
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312142102088.png)

### 3.1套接字地址结构
- 从Linux程序的角度来看，套接字就是一个==有相应描述符的打开文件==，套接字地址放在sockaddr_in这个16字节结构中
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312142103452.png)
- IP地址和端口号总是以网络字节顺序(大端法)存放
- 简化代码示例:typedef struct sockaddr SA;
### 3.2 socket函数
- `int socket(int domain,int type,int protocol)`
	- 创建一个**套接字描述符socket descriptor**
	- 成功返回非负描述符
	- 使用clientfd=Socket(AF_INET,SOCK_STREAM,0);来调用
		- SOCK_STREAM表示这个套接字是连接的一个端点
		- 最好使用getaddrinfo函数来自动生成这些参数
		- clientfd仅上部分打开，不能用于读写。==具体需要取决于是客户端还是服务端==
### 3.3 客户端-connect函数
- `int connect(int clientfd,const struct sockaddr *addr,socklen_t addrlen)`
	- ==客户端==调用，建立与服务器连接
	- 成功则返回0
	- addren=sizeof(sockaddr_in)
	- connect函数会阻塞直到成功连接或发生错误
	- 成功之后clientfd就准备好可以读写了，并且得到了套接字对连接
### 3.4 服务端
####  bind函数
- `int bind(int sockfd,const struct sockaddr *addr,socklen_t addrlen)`
	- 成功返回0
	- 高速内核将addr中的服务器套接字地址和套接字描述符sockfd联系起来
	- addren=sizeof(sockaddr_in)
#### listen函数
- 默认情况，内容认为socket函数创建描述符对应**主动套接字active socket**，存在于连接的客户端
- `int listen(int sockfd,int backlog)`告诉内核，描述符被服务器使用
	- 将sockfd从主动套接字转化为**监听套接字listening socket**，接受来自客户端的连接请求
	- bacolog暗示队列中排队的未完成的连接请求的数量，一般设为较大值
#### accept函数
- `int accept(int listenfd,struct sockaddr *addr,int *addrlen)`
	- 参数是**监听描述符**
		- 作为客户端连接请求的一个端点
		- 被创建一次，存在于服务器整个生命周期
	- 成功则返回非负连接描述符-**已连接描述符conncted descriptor**
		- 连接后建立的连接端点
		- 每次接受连接请求都创建一次
		- 存在于服务器为一个客户端服务的过程中
	- 在addr中填写客户端的套接字地址
	- 等待来自客户端的连接请求
### 3.5 主机和服务的转换
#### getaddrinfo函数
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312142131216.png)

- `int getaddrinfo(const char *host,const char *service,const struct addrinfo *hints,struct addrinfo **result)`
	- 将主机名、主机服务、服务名、端口号的字符串表示转化为套接字地址结构
		- host参数可以是域名或数字地址
			- 对于host关联的每个地址，getaddrinfo最多返回3个addrinfo结构，每个的ai_socktype字段不同(连接、数据报、原始套接字)
		- service可以是服务名(eg:http)，也可以是十进制端口号
			- 如果不想把主机名转换成地址，可以设置host为NULL，service同理
			- 但至少制定其中一个
		- (可选)hints是一个**addinfo结构**,提供更好的列表控制。若传递，只能设置以下字段
			- ai_family
				- AF_INET：IPv4套接字地址
				- AF_INET6：IPv6套接字地址
			- ai_socktype
				- SOCK_STREAM：限制为对每个地址最多一个infoaddr结构
			- ai_protocol
			- ai_flags：位掩码，进一步修改默认行为(具体见CSAPP)
				- AI_ADDRCONFIG
				- AI_CANONNAME
				- AI_NUMERICSERV
				- AI_PASSIVE
			- 其他字段设为0/NULL
	- 可重入，适用于任何协议
	- 返回result
		- result一个指向**addinfo结构的链表**
			- 每个结构指向一个对应于host和service的套接字地址结构
			- 会填写addinfo每个字段(除了ai_flags)
				- ai_addr指向一个套接字地址结构
				- ai_addrlen套接字结构大小
				- ai_next指向列表中下一个addinfo结构
				- 其他字段
			- 字段不透明，可以直接传递给套接字接口中的函数(socket/connect/bind)
	- 如果返回非0的错误代码，调用gai_streeror，将该代码转换为消息字符串
- 调用之后，
	- 客户端会遍历这个链表，尝试每个套接字地址，直到socket和connect成功，建立起连接
	- 服务器会遍历这个链表，尝试每个套接字地址，直到socket和bind成功，描述符会被绑定到一个合法的套接字地址
- `void freeaddrinfo(struct addindo*result)`：避免内存泄漏，释放该链表
#### getnameinfo函数
- 将一个套接字地址结构转换成相应的主机和服务名字符串
- `int getnameinfo(const struct sockaddr *sa,socklen_t salen,char *host,size_t hostlen,char *service,size_t servlen,int flags)`
	- 默认返回host中的域名
		- 默认查找etc/services(如果可能，优先返回服务名而非端口号)
	- sa指向大小为salen字节的套接字地址结构
	- host指向hostlen字节的缓冲区
		- 设置为NULL则不需主机名
	- service指向servlen字节的缓冲区
		- 设置为NULL则不需服务字段
		- 但是和host不可同为NULL
	- flags是位掩码，可以修改默认的行为
		- NI_NUMERICHOST：使函数返回一个数字地址字符串
		- NI_NUMERICSERV：跳过查找，简单返回端口号
	- 将套接字地址结构sa转换成对应的主机和服务名字符串，并复制到host和service缓冲区
	- 如果返回非零的错误代码，调用gai_strerror把它转化为字符串
### 3.6 套接字接口的辅助函数
#### open_clientfd函数(客户端)
- `int open_clientfd(char *hostname,char *port)`
	- 建立与服务器的连接
	- 服务器运行在主机hostname上，并在端口号port上监听连接请求
	- 返回一个打开的套接字描述符
- 代码详见CSAPP
#### open_listenfd函数(服务器)
- `int open_listenfd(char *port)`
	- 创建**监听描述符**，准备好接收连接请求
	- 若成功返回该描述符
- 代码详见CSAPP
### 3.7 echo客户端和服务器示例
- 简易的实现实例代码
- 具体见CSAPP
- 简单的echo服务器一次只能处理一个客户端，称为**迭代服务器iterative server**
	- 进阶：**并发服务器concurrent server**
## 4.Web服务器
### 4.1 Web基础
- Web客户端和服务器之间的交互用的是一个基于文本的应用级协议，叫做**HTTP(Hypertext Transfer Protocol)超文本传输协议**
- Web内容用**HTML**语言编写
### 4.2 Web内容
- **内容**是与一个MIME类型相关的字节序列
- Web服务器以两种不同的方式向客户端提供内容：
	- 取一个磁盘文件，并将它的内容返回给客户端，称为**静态内容static content**，这一过程叫做**服务静态内容serving static content**
	- 运行一个可执行文件，将输出返回给客户端，称为**动态内容dynamic content**，这一过程叫做**服务动态内容serving dynamic content**
- 每条返回的内容都是和它管理的某个文件相关联的，每一个文件都有一个唯一的名字，叫做**URL通用资源定位符**
	- ?字符分隔文件名和参数
	- &字符分隔每个参数
	- 事务过程中，客户端和服务器使用URL的不同部分
		- ==客户端使用前缀来决定==
			- 与哪类服务器联系
			- 服务器在哪里
			- 监听的端口号
		- ==服务器使用后缀来决定==
			- 发现文件
			- 确定请求静态还是动态内容
	- 注意
		- 确定URL指向静态还是动态没有标准规则，一般把所有可执行文件放在一组目录中
		- 后缀中开始的'/'不代表根目录，而是被请求内容的主目录
		- 最小的URL后缀是'/'字符，服务器默认扩展为某个默认的主页
### 4.3 HTTP事务
- **TELNET程序**：和因特网上的任何Web服务器执行事务
- 发起事务
	- 我们输入HTTP请求
	- 服务器返回HTTP响应
#### HTTP请求
- 一个**请求行request line**
	- 格式：==method URI version==
		- method我们只讨论GET方法(还有POST/OPTIONS等方法)
		- URI是URL的后缀，包含文件名和可选参数
		- version字段表明请求遵循的HTTP版本
			- 最新的是HTTP/1.1：允许客户端和服务器在同一条**持久连接**上执行多个事务
- 0或多个**请求报头request header**
	- 提供额外信息
	- 格式：==header-name:header-data**
	- 关注**Host报头**，在HTTP/1.1中需要，HTTP/1.0中不需要
		- **代理缓存proxy cache**使用Host报头
			- 作为**原始服务器Origin server**的中介
			- 客户端和服务器之间可以有多个代理，成为**代理链**
			- Host报头数据指示原始服务器的域名，使得代理链中的代理判断能否在本地缓存中拥有一个被请求内容的副本
- 一个空的文本行：终止报头列表
#### HTTP响应
- 一个**响应行response line**
	- 格式：==version status-code status-message==
		- version:HTTP version
		- **status-code状态码**：3位正整数，指明对请求的处理
		- **status-message状态消息**：与错误代码等价的英文描述
![image.png](https://zhangzinuo.oss-cn-beijing.aliyuncs.com/img/202312142216917.png)

- 0或多个**响应报头response header**
	- Content-Type:告诉客户端内容的MIME类型
	- Content-Length：指示响应主体的字节大小
- 一个空行：终止报头
- 一个**响应主体response body**：包含被请求的内容
### 4.4 服务动态内容
**GCI**解决以下问题
- 客户端如何将程序参数传递给服务器
	- 参数中不允许有空格，必须用%20表示
	- HOST POST请求的参数是在请求主体中而不是URI中传递的
- 客户端如何将参数传递给子进程
	- fork, execve在子进程上下文中执行请求的程序
	- 这样的程序叫做**GCI程序/GCI脚本**
	- 调用execve函数前，将GCI环境变量QUERY_STRING设置为"15000&213"，程序在运行时使用getenv函数来引用它
- 服务器如何将其他信息传递给子进程
	- 定义大量环境变量，GCI程序运行时会设置
- 子进程将输出发送到哪里
	- 发送到标准输出
	- 在子进程加载并运行GCI程序一起，使用dup2函数将标准输出**重定向**到和客户端相关联的已连接描述符
	- 这样发送到标准输出的东西==实际上直接到达客户端==
	- 注意：子进程要负责生成Content-type和Content-length响应报头，以及终止报头的空行
## 5.TINY Web服务器
- 为实际的浏览器提供静态和动态的内容
- 详见CSAPP
###  main程序
### doit函数
### clienterror函数
### read_requesthdrs函数
### parse_uri函数
### serve_static函数
### serve_dynamic函数
# 第十二章.并发编程
- 前两节回课已准备，略
## 1.并发编程的必要性和困难
## 2.并发编程实现
### 2.1 基于进程的并发编程
### 2.2 基于I/O多路复用的并发编程
### 2.3 基于线程的并发编程
## 3.同步
### 3.1 共享变量同步线程
#### 3.1.1 线程内存模型
- 寄存器从不共享
- 虚拟内存总是共享
	- 进程上下文的只读文本、读/写数据、堆、所有共享代码和数据区域
	- 共享相同打开文件的集合
- 各自独立的线程栈的内存模型不是那么整齐清楚
	- 被保存在虚拟地址空间的栈区域中，被相应的线程独立访问
	- 但对其他线程是不设防的
#### 3.1.2 将变量映射到内存
>  多线程的C程序中变量根据它们的存储类型被映射到虚拟内存：

- **全局变量**：虚拟内存的读/写区域只包含每个全局变量的一个实例-任何线程都可以引用
- **本地自动变量**：定义在函数内部没有static属性的变量
	- 运行时每个线程的栈都包含它自己的本地自动变量的实例
	- 即使多个线程执行同一个线程例程
- **本地静态变量**：函数内部static变量，其虚拟内存的读/写区域只包含在程序中声明的每个本地静态变量的一个实力，所以对等线程读写这一个实例
#### 3.1.3 共享变量
- 一个变量v是==共享==的<-->它的一个实例被一个以上的线程引用
- 本地自动变量事实上也是能被共享的
### 3.2 信号量同步线程
- 共享变量引入了**同步错误synchronization error**的可能性
	- ==一般而言，无法预测操作系统是否将为线程选择一个正确的顺序==
#### 3.2.1 进度图progress graph
- 将n个并发线程的执行模型化为一条n维笛卡尔空间中的轨迹线
	- 每条轴k对应于线程k的进度
	- 每个点($I_1,I_2,...,I_n$)代表线程k已经完成了指令$I_k$这一状态
	- 图的原点对应于没有任何线程完成一条指令的**初始状态**
- 将指令模型化为从一种状态到另一种状态的**转换transition**
	- 被表示为一条从一点到相邻点的有向边
	- 合法的转换是向右或者向上的
		- 程序不会反向运行
	- 两条指令不能在同一时刻完成——对角线转换是不允许的
- 对于线程i，其操作某个共享变量内容的指令构成了一个关于该共享变量的**临界区critical section**
	- 不与其他进程的临界区交替执行
	- 确保每个线程在执行临界区中的指令时，拥有对共享变量的**互斥的访问mutually exclusive access**，这种现象称为**互斥mutual exclusion**
	- 两个临界区的交集形成的状态空间叫做**不安全区unsafe region**
		- 不安全区和它交界的状态相邻，但并不包括这些状态
		- 绕开不安全区的轨迹线叫做**安全轨迹线safe trajectroy**
		- 接触到任何不安全区的轨迹线叫做**不安全轨迹线**
#### 3.2.2 信号量semaphore
- 信号量s是具有非负整数值的全局变量，只能由两种特殊的操作来处理
	- P(s)：
		- 如果s非零，P将s减1，并立即返回
		- 如果s为零，就挂起这个线程，直到s变为非0
			- V操作重启之后，P将s减1，并将控制返回给调用者
	- V(s)：
		- 将s加1
		- 如果有任何线程阻塞在P操作等待s变成非0，V会重启这些线程中的一个，然后将s减1，完成它的P操作
			- 当有多个线程在等待同一个信号量时，不能预测V操作要重启哪一个线程
	- P的减1和V的加1操作都是不可分割(不能中断)的
	- P和V保证一个正在运行的程序不会进入**信号量不变形**(即一个正确初始化了的信号量有一个负值)
- Posix标准定义了许多操作信号量的函数
	- `int sem_init(sem_t *sem,0,unsigned int value)`:将信号量sem初始化为value
		- 每个信号量在使用前必须初始化
	- `int sem_wait(sem_t *s)` :P(s) 包装：`void P(sem_t *s)`
	- `int sem_post(sem_t *s)`: V(s) 包装：`void V(sem_t *s)`
#### 3.2.3 信号量实现互斥
- 确保对共享变量的互斥访问：**二元信号量binary semaphore**，它的值总是0或1
	- **将每个共享变量(或者一组相关的共享变量)与一个信号量s(初始为1)联系起来，然后用P(s)和V(s)操作将相应的临界区包围起来**
- 以提供互斥为目的的二元信号量也称为**互斥锁**
	- 在一个互斥锁上执行P操作成为对互斥锁**加锁**
		- 还未解锁的线程称为**占用**这个互斥锁
	- 执行V操作成为对互斥锁**解锁**
- 一个被用作一组可用资源的计数器的信号量被称为**计数信号量**
- 关键思想是使用P和V创建了一组状态，叫做**禁止区**，其中信号量s<0
	- 因为信号量不变性，没有实际可行的轨迹线能够包含禁止区中的状态
	- 且禁止区包含不安全区，则每条实际可行的轨迹线都是安全的
	- 从而确保对临界区的互斥访问
- 实现：
	- 声明信号量mutex，初始化为1
	- 在对共享变量的操作包围P和V操作
#### 3.2.4 信号量调度共享资源
##### 生产者-消费者问题
- 生产者和消费者线程共享一个有n个槽的**有效缓冲区**
	- 生产者线程反复地生成新的**项目item**，并插入到缓冲区
	- 消费者线程不断取出这些项目
- 对缓冲区的访问
	- 互斥
	- 调度：
		- 如果满，生产者等待槽位变为可用
		- 如果空，消费者等待有一个项目可用
- 实现：**SBUF包**，构造基于**预线程化prethreading**的并发服务器
	- 结构类型为sbuf_t的有限缓冲区
	- `sbuf_init`：
		- 为缓冲区分配堆内存
		- 设置front和rear表示一个空的缓冲区
		- 为三个信号量赋初始值
	- `sbuf_deinit`
		- 释放缓冲区存储
	- `sbuf_insert`
		- 等待一个可用的槽位
		- 对互斥锁加锁
		- 添加项目
		- 对互斥锁解锁
		- 宣布有新项目可用
	- `sbuf_remove`
		- 与sbuf_insert函数对称
		- 等待一个可用的缓冲区项目
		- 加锁
		- 取出项目
		- 解锁
		- 宣布有新槽位可供使用
##### 读者-写者问题
- 修改对象的线程叫做**写者**，只读对象的线程叫做**读者**
	- 有无限多个并发的读者和写者
- 变种
	- **读者优先**：要求不要让读者等待，除非已经把使用对象的权限给了一个写者
		- 读者不会因为有一个写者在等待而等待
		- 简单解答(见CSAPP)：可能导致**饥饿starvation**
	- **写者优先**：一旦一个写者准备好可以写，它就会尽可能快地完成它的写操作
		- 在一个写者后到达的读者必须等待，即使这个写者也是在等待
#### 3.2.5 基于预线程化的并发服务器
详见CSAPP
### 3.3 使用线程提高并行性
- 我们曾假设并发线程在单处理器系统上执行，但是大多数现代机器具有多核处理器
- 程序分类
	- 所有程序的集合能够划分成不相交的
		- **顺序程序集合**
			- 写顺序程序只有一条逻辑流
		- **并发程序集合**
			- 有多条并发流
			- **并行程序**是一个运行在多个处理器上的并发程序，是并发程序的真子集
- 并行编程
	- 注意**同步开销巨大(P与V的调用)**，要尽可能避免。
		- 如果不可避免，要用尽可能多的有用计算弥补这个开销
#### 刻画并行程序的性能
- **加速比speedup**：$S_p=T_1/T_p$(**强拓展**)
	- p是处理器核的数量
	- Tk是在k个核上运动时间
	- T1
		- 顺序执行时间，Sp称为**绝对加速比**
			- 可以更加真实地衡量并行度好处
			- 更难测量
		- 并行版本在一个核上的执行实现，Sp称为**相对加速比**
			- 即使一个核，也会受到同步开销的影响
- **效率**$E_p=S_p/p=T_1/{pT_p}$
	- 通常表示范围在(0,100]之间的百分比
	- 是对由于并行化造成的开销的衡量
	- 具有高效率的程序在有用的工作上花费更多时间，在同步和通信上花费更少时间
- **弱扩展**加速比：在增加处理器数量的同时，增加问题的规模，由此计算单位时间内完成的工作总量
	- 比强扩展更真实的衡量值
### 3.4其他并发问题
#### 3.4.1 线程安全thread safety
- 一个函数被称为**线程安全的thread-safe**，当且仅当被多个并发线程反复调用时会一直产生正确的结果——与之相对为**线程不安全**
- 4个线程不安全类函数
	- **不保护共享变量的函数**
		- 利用P和V保护共享变量解决
			- 优点：调用程序不需要做任何修改
			- 缺点：同步操作将减慢程序的执行时间
	- **保持跨越多个调用的状态的函数**
		- 唯一解决方法：重写，使之不再使用任何static数据，而依靠调用者在参数中传递状态信息
	- **返回指向静态变量的指针的函数**
		- 方法1：重写函数，使调用者传递存放结果的变量的地址
			- 消除所有共享数据
		- 方法2：**加锁-复制lock-and-copy**(示例见CSAPP_717页)
			- 将线程不安全函数与互斥锁连接起来
			- 在每一个调用位置，对互斥锁加锁，调用线程不安全函数，将函数返回的结果复制到一个私有的内存位置，然后解锁
			- 定义一个线程安全的包装函数，以减少对调用者的修改
				- 执行加锁-复制，通过调用这个包装函数取代对线程不安全函数的引用
	- **调用线程不安全函数的函数**
		- f调用线程不安全函数g
		- g是2类函数：f也是线程不安全，只能重写
		- g是1/4类函数：利用互斥锁可以保护f的安全性
#### 3.4.2 可重入性
- **可重入函数reentrant function**：当它被多个线程调用时，不会引用任何共享数据
	- 为线程安全函数的一个==真子集==
	- **显式可重入**：所有函数参数都是传值传递的，所以数据引用都是本地的自动栈变量
	- **隐式可重入**：调用线程小心地传递指向共享数据的==指针==
- 可重入性有时==既是调用者也是被调用者==的属性
#### 3.4.3 在线程化的程序中使用已存在的库函数
- 一些线程不安全的库函数
	- 二类
		- rand
		- strtok
	- 三类:返回一个指向静态变量的指针
		- asctime,ctime,localtime
		- gethostbyname,gethostbyaddr,inet-ntop
- 加锁-复制方法带来的缺点：
	- 额外同步降低速度
	- gethostbyname这样的函数返回指向复杂结构的指针，要复制的话需要**深层复制**结构
	- 对rand这样的2类函数不有效
- 不安全函数的可重入版本:"\_r"结尾
#### 3.4.4 竞争race
- 当一个程序的正确性依赖于一个线程要在另一个线程到达y点之前到达它的控制流中的x点时，就会发生**竞争race**
- 示例见CSAPP即可，解决策略是手动malloc为每一个操作分配一个独立的块传递过去(记得释放)
#### 3.4.5 死锁deadlock
- 进程图中，死锁表示为：
	- 使用P和V顺序不当，导致两个信号量的禁止区域重叠，==重叠的禁止区阻碍了每个合法方向上的进展==，导致**死锁区域**状态
		- 也就是说：每个线程都在等待其他线程执行一个根本不可能发生的V操作
	- 如果轨迹线恰好进入了死锁区域，死锁不可避免，且无法离开
	- 死锁不可预测，因为不同执行有不同的轨迹线
- 当使用二元信号量来实现互斥时，以下规则避免死锁，**互斥锁加锁顺序规则**
	- **给定所有互斥操作的一个全序，如果每个线程都是以一种顺序获得互斥锁并以相反的顺序释放，那么这个程序就是无死锁的**





